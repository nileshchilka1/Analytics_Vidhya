{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import missingno\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>464018</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>464685</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>465406</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>33</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>467299</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>27</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>461879</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Gender Ever_Married  Age Graduated     Profession  \\\n",
       "0     462809    Male           No   22        No     Healthcare   \n",
       "1     462643  Female          Yes   38       Yes       Engineer   \n",
       "2     466315  Female          Yes   67       Yes       Engineer   \n",
       "3     461735    Male          Yes   67       Yes         Lawyer   \n",
       "4     462669  Female          Yes   40       Yes  Entertainment   \n",
       "...      ...     ...          ...  ...       ...            ...   \n",
       "8063  464018    Male           No   22        No            NaN   \n",
       "8064  464685    Male           No   35        No      Executive   \n",
       "8065  465406  Female           No   33       Yes     Healthcare   \n",
       "8066  467299  Female           No   27       Yes     Healthcare   \n",
       "8067  461879    Male          Yes   37       Yes      Executive   \n",
       "\n",
       "      Work_Experience Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0                 1.0            Low          4.0  Cat_4            D  \n",
       "1                 NaN        Average          3.0  Cat_4            A  \n",
       "2                 1.0            Low          1.0  Cat_6            B  \n",
       "3                 0.0           High          2.0  Cat_6            B  \n",
       "4                 NaN           High          6.0  Cat_6            A  \n",
       "...               ...            ...          ...    ...          ...  \n",
       "8063              0.0            Low          7.0  Cat_1            D  \n",
       "8064              3.0            Low          4.0  Cat_4            D  \n",
       "8065              1.0            Low          1.0  Cat_6            D  \n",
       "8066              1.0            Low          4.0  Cat_6            B  \n",
       "8067              0.0        Average          3.0  Cat_4            B  \n",
       "\n",
       "[8068 rows x 11 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married       140\n",
       "Age                  0\n",
       "Graduated           78\n",
       "Profession         124\n",
       "Work_Experience    829\n",
       "Spending_Score       0\n",
       "Family_Size        335\n",
       "Var_1               76\n",
       "Segmentation         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Gender               0\n",
       "Ever_Married        50\n",
       "Age                  0\n",
       "Graduated           24\n",
       "Profession          38\n",
       "Work_Experience    269\n",
       "Spending_Score       0\n",
       "Family_Size        113\n",
       "Var_1               32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonIDlist = list(set(train_df[\"ID\"]) & set(test_df[\"ID\"]))\n",
    "commonIDlist = pd.DataFrame(commonIDlist,columns=[\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonIDlist= commonIDlist.merge(train_df[['ID','Segmentation']],on=\"ID\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>466951</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466954</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466955</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>466956</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>466961</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>466926</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>466927</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>466936</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>466938</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>466939</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2332 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Segmentation\n",
       "0     466951            C\n",
       "1     466954            C\n",
       "2     466955            A\n",
       "3     466956            B\n",
       "4     466961            C\n",
       "...      ...          ...\n",
       "2327  466926            D\n",
       "2328  466927            D\n",
       "2329  466936            C\n",
       "2330  466938            A\n",
       "2331  466939            B\n",
       "\n",
       "[2332 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commonIDlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('ID',axis=1,inplace=True)\n",
    "test_df.drop('ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Ever_Married'].isnull(),'Ever_Married'] = np.where(train_df[train_df['Ever_Married'].isnull()]['Family_Size']==1,'No',train_df[train_df['Ever_Married'].isnull()]['Ever_Married'] )\n",
    "test_df.loc[test_df['Ever_Married'].isnull(),'Ever_Married'] = np.where(test_df[test_df['Ever_Married'].isnull()]['Family_Size']==1,'No',test_df[test_df['Ever_Married'].isnull()]['Ever_Married'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Ever_Married'].isnull(),'Ever_Married'] = np.where(train_df[train_df['Ever_Married'].isnull()]['Age']<=24,'No','Yes')\n",
    "test_df.loc[test_df['Ever_Married'].isnull(),'Ever_Married'] = np.where(test_df[test_df['Ever_Married'].isnull()]['Age']<=24,'No','Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Graduated'].isnull(),'Graduated'] = np.where(train_df[train_df['Graduated'].isnull()]['Age']<=23,'No',train_df.loc[train_df['Graduated'].isnull(),'Graduated'])\n",
    "test_df.loc[test_df['Graduated'].isnull(),'Graduated'] = np.where(test_df[test_df['Graduated'].isnull()]['Age']<=23,'No',test_df.loc[test_df['Graduated'].isnull(),'Graduated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Graduated'].isnull(),'Graduated'] = np.where((train_df[train_df['Graduated'].isnull()]['Profession']=='Entertainment') | (train_df[train_df['Graduated'].isnull()]['Profession']=='Homemaker'),'No','Yes'  )\n",
    "test_df.loc[test_df['Graduated'].isnull(),'Graduated'] = np.where((test_df[test_df['Graduated'].isnull()]['Profession']=='Entertainment') | (test_df[test_df['Graduated'].isnull()]['Profession']=='Homemaker'),'No','Yes'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Profession'].fillna('Artist',inplace=True)\n",
    "test_df['Profession'].fillna('Artist',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Family_Size'] = np.where(train_df['Family_Size']>=6,'Large',train_df['Family_Size'])\n",
    "test_df['Family_Size'] = np.where(test_df['Family_Size']>=6,'Large',test_df['Family_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Family_Size'] = train_df['Family_Size'].astype(str)\n",
    "test_df['Family_Size'] = test_df['Family_Size'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Family_Size'] = np.where(train_df['Family_Size']=='1.0','Single',train_df['Family_Size'])\n",
    "test_df['Family_Size'] = np.where(test_df['Family_Size']=='1.0','Single',test_df['Family_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Family_Size'] = np.where((train_df['Family_Size']=='2.0') | (train_df['Family_Size']=='3.0') ,'Small',train_df['Family_Size'])\n",
    "test_df['Family_Size'] = np.where((test_df['Family_Size']=='2.0') | (test_df['Family_Size']=='3.0') ,'Small',test_df['Family_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Family_Size'] = np.where((train_df['Family_Size']=='4.0') | (train_df['Family_Size']=='5.0') ,'Medium',train_df['Family_Size'])\n",
    "test_df['Family_Size'] = np.where((test_df['Family_Size']=='4.0') | (test_df['Family_Size']=='5.0') ,'Medium',test_df['Family_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Family_Size'] = np.where(train_df['Family_Size']=='nan','Small',train_df['Family_Size'])\n",
    "test_df['Family_Size'] = np.where(test_df['Family_Size']=='nan','Small',test_df['Family_Size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['Var_1'].isnull(),'Var_1'] = np.where(train_df[train_df['Var_1'].isnull()]['Spending_Score']=='Low','Cat_5',train_df[train_df['Var_1'].isnull()]['Var_1'] )\n",
    "test_df.loc[test_df['Var_1'].isnull(),'Var_1'] = np.where(test_df[test_df['Var_1'].isnull()]['Spending_Score']=='Low','Cat_5',test_df[test_df['Var_1'].isnull()]['Var_1'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Var_1'].fillna('Cat_6',inplace=True)\n",
    "test_df['Var_1'].fillna('Cat_6',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Work_Experience'].fillna(0.0,inplace=True)\n",
    "test_df['Work_Experience'].fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Gender'] = np.where(train_df['Gender']=='Male',0,1)\n",
    "test_df['Gender'] = np.where(test_df['Gender']=='Male',0,1)\n",
    "\n",
    "train_df['Ever_Married'] = np.where(train_df['Ever_Married']=='Yes',1,0)\n",
    "test_df['Ever_Married'] = np.where(test_df['Ever_Married']=='Yes',1,0)\n",
    "\n",
    "train_df['Graduated'] = np.where(train_df['Graduated']=='Yes',1,0)\n",
    "test_df['Graduated'] = np.where(test_df['Graduated']=='Yes',1,0)\n",
    "\n",
    "\n",
    "train_df['Spending_Score'] = train_df['Spending_Score'].map({'Low':0 ,'Average':1,'High':2}) \n",
    "test_df['Spending_Score'] = test_df['Spending_Score'].map({'Low':0 ,'Average':1,'High':2}) \n",
    "\n",
    "train_df['Family_Size'] = train_df['Family_Size'].map({'Single':0 ,'Small':1,'Medium':2,'Large':3})\n",
    "test_df['Family_Size'] = test_df['Family_Size'].map({'Single':0 ,'Small':1,'Medium':2,'Large':3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df.drop(['Profession','Var_1'],axis=1),pd.get_dummies(train_df['Profession']),pd.get_dummies(train_df['Var_1'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df.drop(['Profession','Var_1'],axis=1),pd.get_dummies(test_df['Profession']),pd.get_dummies(test_df['Var_1'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Segmentation'] = train_df['Segmentation'].map({'A':0 ,'B':1,'C':2,'D':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Age'] = np.log(train_df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Segmentation</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Engineer</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Executive</th>\n",
       "      <th>Healthcare</th>\n",
       "      <th>Homemaker</th>\n",
       "      <th>Lawyer</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>Cat_1</th>\n",
       "      <th>Cat_2</th>\n",
       "      <th>Cat_3</th>\n",
       "      <th>Cat_4</th>\n",
       "      <th>Cat_5</th>\n",
       "      <th>Cat_6</th>\n",
       "      <th>Cat_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.637586</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.204693</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.688879</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.091042</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Ever_Married       Age  Graduated  Work_Experience  \\\n",
       "0          0             0  3.091042          0              1.0   \n",
       "1          1             1  3.637586          1              0.0   \n",
       "2          1             1  4.204693          1              1.0   \n",
       "3          0             1  4.204693          1              0.0   \n",
       "4          1             1  3.688879          1              0.0   \n",
       "...      ...           ...       ...        ...              ...   \n",
       "8063       0             0  3.091042          0              0.0   \n",
       "8064       0             0  3.555348          0              3.0   \n",
       "8065       1             0  3.496508          1              1.0   \n",
       "8066       1             0  3.295837          1              1.0   \n",
       "8067       0             1  3.610918          1              0.0   \n",
       "\n",
       "      Spending_Score  Family_Size  Segmentation  Artist  Doctor  Engineer  \\\n",
       "0                  0            2             3       0       0         0   \n",
       "1                  1            1             0       0       0         1   \n",
       "2                  0            0             1       0       0         1   \n",
       "3                  2            1             1       0       0         0   \n",
       "4                  2            3             0       0       0         0   \n",
       "...              ...          ...           ...     ...     ...       ...   \n",
       "8063               0            3             3       1       0         0   \n",
       "8064               0            2             3       0       0         0   \n",
       "8065               0            0             3       0       0         0   \n",
       "8066               0            2             1       0       0         0   \n",
       "8067               1            1             1       0       0         0   \n",
       "\n",
       "      Entertainment  Executive  Healthcare  Homemaker  Lawyer  Marketing  \\\n",
       "0                 0          0           1          0       0          0   \n",
       "1                 0          0           0          0       0          0   \n",
       "2                 0          0           0          0       0          0   \n",
       "3                 0          0           0          0       1          0   \n",
       "4                 1          0           0          0       0          0   \n",
       "...             ...        ...         ...        ...     ...        ...   \n",
       "8063              0          0           0          0       0          0   \n",
       "8064              0          1           0          0       0          0   \n",
       "8065              0          0           1          0       0          0   \n",
       "8066              0          0           1          0       0          0   \n",
       "8067              0          1           0          0       0          0   \n",
       "\n",
       "      Cat_1  Cat_2  Cat_3  Cat_4  Cat_5  Cat_6  Cat_7  \n",
       "0         0      0      0      1      0      0      0  \n",
       "1         0      0      0      1      0      0      0  \n",
       "2         0      0      0      0      0      1      0  \n",
       "3         0      0      0      0      0      1      0  \n",
       "4         0      0      0      0      0      1      0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...  \n",
       "8063      1      0      0      0      0      0      0  \n",
       "8064      0      0      0      1      0      0      0  \n",
       "8065      0      0      0      0      0      1      0  \n",
       "8066      0      0      0      0      0      1      0  \n",
       "8067      0      0      0      1      0      0      0  \n",
       "\n",
       "[8068 rows x 24 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Engineer</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Executive</th>\n",
       "      <th>Healthcare</th>\n",
       "      <th>Homemaker</th>\n",
       "      <th>Lawyer</th>\n",
       "      <th>Marketing</th>\n",
       "      <th>Cat_1</th>\n",
       "      <th>Cat_2</th>\n",
       "      <th>Cat_3</th>\n",
       "      <th>Cat_4</th>\n",
       "      <th>Cat_5</th>\n",
       "      <th>Cat_6</th>\n",
       "      <th>Cat_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2627 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Ever_Married  Age  Graduated  Work_Experience  Spending_Score  \\\n",
       "0          1             1   36          1              0.0               0   \n",
       "1          0             1   37          1              8.0               1   \n",
       "2          1             1   69          0              0.0               0   \n",
       "3          0             1   59          0             11.0               2   \n",
       "4          1             0   19          0              0.0               0   \n",
       "...      ...           ...  ...        ...              ...             ...   \n",
       "2622       0             0   29          0              9.0               0   \n",
       "2623       1             0   35          1              1.0               0   \n",
       "2624       1             0   53          1              0.0               0   \n",
       "2625       0             1   47          1              1.0               2   \n",
       "2626       1             0   43          1              9.0               0   \n",
       "\n",
       "      Family_Size  Artist  Doctor  Engineer  Entertainment  Executive  \\\n",
       "0               0       0       0         1              0          0   \n",
       "1               2       0       0         0              0          0   \n",
       "2               0       1       0         0              0          0   \n",
       "3               1       0       0         0              0          1   \n",
       "4               2       0       0         0              0          0   \n",
       "...           ...     ...     ...       ...            ...        ...   \n",
       "2622            2       0       0         0              0          0   \n",
       "2623            0       0       1         0              0          0   \n",
       "2624            1       0       0         0              1          0   \n",
       "2625            2       0       0         0              0          1   \n",
       "2626            1       0       0         0              0          0   \n",
       "\n",
       "      Healthcare  Homemaker  Lawyer  Marketing  Cat_1  Cat_2  Cat_3  Cat_4  \\\n",
       "0              0          0       0          0      0      0      0      0   \n",
       "1              1          0       0          0      0      0      0      0   \n",
       "2              0          0       0          0      0      0      0      0   \n",
       "3              0          0       0          0      0      0      0      0   \n",
       "4              0          0       0          1      0      0      0      0   \n",
       "...          ...        ...     ...        ...    ...    ...    ...    ...   \n",
       "2622           1          0       0          0      0      0      0      0   \n",
       "2623           0          0       0          0      0      0      0      0   \n",
       "2624           0          0       0          0      0      0      0      0   \n",
       "2625           0          0       0          0      0      0      0      1   \n",
       "2626           1          0       0          0      0      0      0      0   \n",
       "\n",
       "      Cat_5  Cat_6  Cat_7  \n",
       "0         0      1      0  \n",
       "1         0      1      0  \n",
       "2         0      1      0  \n",
       "3         0      1      0  \n",
       "4         0      1      0  \n",
       "...     ...    ...    ...  \n",
       "2622      0      1      0  \n",
       "2623      0      1      0  \n",
       "2624      0      1      0  \n",
       "2625      0      0      0  \n",
       "2626      0      0      1  \n",
       "\n",
       "[2627 rows x 23 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('Segmentation',axis=1)\n",
    "y = train_df['Segmentation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['learning_rate'] = 0.1\n",
    "params['max_depth'] = 18\n",
    "params['n_estimators'] = 2000\n",
    "params['objective'] = 'multiclass'\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['subsample'] = 0.7\n",
    "params['colsample_bytree']=1\n",
    "params['min_data_in_leaf'] = 55\n",
    "params['reg_alpha'] = 1\n",
    "params['reg_lambda'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_error: 0.644407\ttraining's multi_logloss: 1.34175\tvalid_1's multi_error: 0.645601\tvalid_1's multi_logloss: 1.34509\n",
      "Training until validation scores don't improve for 1000 rounds\n",
      "[2]\ttraining's multi_error: 0.520297\ttraining's multi_logloss: 1.30599\tvalid_1's multi_error: 0.536555\tvalid_1's multi_logloss: 1.31335\n",
      "[3]\ttraining's multi_error: 0.470251\ttraining's multi_logloss: 1.2753\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.28609\n",
      "[4]\ttraining's multi_error: 0.461419\ttraining's multi_logloss: 1.24829\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.26318\n",
      "[5]\ttraining's multi_error: 0.458475\ttraining's multi_logloss: 1.22461\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.24224\n",
      "[6]\ttraining's multi_error: 0.455067\ttraining's multi_logloss: 1.20304\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.22363\n",
      "[7]\ttraining's multi_error: 0.452278\ttraining's multi_logloss: 1.18441\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.20812\n",
      "[8]\ttraining's multi_error: 0.451658\ttraining's multi_logloss: 1.16758\tvalid_1's multi_error: 0.486989\tvalid_1's multi_logloss: 1.19433\n",
      "[9]\ttraining's multi_error: 0.444995\ttraining's multi_logloss: 1.15208\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.18162\n",
      "[10]\ttraining's multi_error: 0.443756\ttraining's multi_logloss: 1.13852\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.17085\n",
      "[11]\ttraining's multi_error: 0.444221\ttraining's multi_logloss: 1.1258\tvalid_1's multi_error: 0.477076\tvalid_1's multi_logloss: 1.16055\n",
      "[12]\ttraining's multi_error: 0.443446\ttraining's multi_logloss: 1.11474\tvalid_1's multi_error: 0.475217\tvalid_1's multi_logloss: 1.15158\n",
      "[13]\ttraining's multi_error: 0.443291\ttraining's multi_logloss: 1.10457\tvalid_1's multi_error: 0.473358\tvalid_1's multi_logloss: 1.14384\n",
      "[14]\ttraining's multi_error: 0.442206\ttraining's multi_logloss: 1.09492\tvalid_1's multi_error: 0.477076\tvalid_1's multi_logloss: 1.13686\n",
      "[15]\ttraining's multi_error: 0.438953\ttraining's multi_logloss: 1.08645\tvalid_1's multi_error: 0.475836\tvalid_1's multi_logloss: 1.13058\n",
      "[16]\ttraining's multi_error: 0.437713\ttraining's multi_logloss: 1.07865\tvalid_1's multi_error: 0.477076\tvalid_1's multi_logloss: 1.12502\n",
      "[17]\ttraining's multi_error: 0.437093\ttraining's multi_logloss: 1.0717\tvalid_1's multi_error: 0.477695\tvalid_1's multi_logloss: 1.12029\n",
      "[18]\ttraining's multi_error: 0.435079\ttraining's multi_logloss: 1.06507\tvalid_1's multi_error: 0.473978\tvalid_1's multi_logloss: 1.11622\n",
      "[19]\ttraining's multi_error: 0.433994\ttraining's multi_logloss: 1.05864\tvalid_1's multi_error: 0.471499\tvalid_1's multi_logloss: 1.11215\n",
      "[20]\ttraining's multi_error: 0.43229\ttraining's multi_logloss: 1.05301\tvalid_1's multi_error: 0.471499\tvalid_1's multi_logloss: 1.10883\n",
      "[21]\ttraining's multi_error: 0.429656\ttraining's multi_logloss: 1.0478\tvalid_1's multi_error: 0.469021\tvalid_1's multi_logloss: 1.10546\n",
      "[22]\ttraining's multi_error: 0.428726\ttraining's multi_logloss: 1.04272\tvalid_1's multi_error: 0.472119\tvalid_1's multi_logloss: 1.10249\n",
      "[23]\ttraining's multi_error: 0.427332\ttraining's multi_logloss: 1.03804\tvalid_1's multi_error: 0.469021\tvalid_1's multi_logloss: 1.09975\n",
      "[24]\ttraining's multi_error: 0.426402\ttraining's multi_logloss: 1.03369\tvalid_1's multi_error: 0.469021\tvalid_1's multi_logloss: 1.09734\n",
      "[25]\ttraining's multi_error: 0.424543\ttraining's multi_logloss: 1.02948\tvalid_1's multi_error: 0.47026\tvalid_1's multi_logloss: 1.09536\n",
      "[26]\ttraining's multi_error: 0.423303\ttraining's multi_logloss: 1.02561\tvalid_1's multi_error: 0.476456\tvalid_1's multi_logloss: 1.09375\n",
      "[27]\ttraining's multi_error: 0.424698\ttraining's multi_logloss: 1.02165\tvalid_1's multi_error: 0.474597\tvalid_1's multi_logloss: 1.09202\n",
      "[28]\ttraining's multi_error: 0.423613\ttraining's multi_logloss: 1.01791\tvalid_1's multi_error: 0.475217\tvalid_1's multi_logloss: 1.09055\n",
      "[29]\ttraining's multi_error: 0.422374\ttraining's multi_logloss: 1.01405\tvalid_1's multi_error: 0.473358\tvalid_1's multi_logloss: 1.08856\n",
      "[30]\ttraining's multi_error: 0.421599\ttraining's multi_logloss: 1.01035\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.08688\n",
      "[31]\ttraining's multi_error: 0.420514\ttraining's multi_logloss: 1.00733\tvalid_1's multi_error: 0.473358\tvalid_1's multi_logloss: 1.08596\n",
      "[32]\ttraining's multi_error: 0.4185\ttraining's multi_logloss: 1.00429\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.0847\n",
      "[33]\ttraining's multi_error: 0.41819\ttraining's multi_logloss: 1.00151\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.08369\n",
      "[34]\ttraining's multi_error: 0.41819\ttraining's multi_logloss: 0.998921\tvalid_1's multi_error: 0.474597\tvalid_1's multi_logloss: 1.08268\n",
      "[35]\ttraining's multi_error: 0.416796\ttraining's multi_logloss: 0.996389\tvalid_1's multi_error: 0.472119\tvalid_1's multi_logloss: 1.08177\n",
      "[36]\ttraining's multi_error: 0.415401\ttraining's multi_logloss: 0.993918\tvalid_1's multi_error: 0.469641\tvalid_1's multi_logloss: 1.08058\n",
      "[37]\ttraining's multi_error: 0.415401\ttraining's multi_logloss: 0.99149\tvalid_1's multi_error: 0.473358\tvalid_1's multi_logloss: 1.08011\n",
      "[38]\ttraining's multi_error: 0.414472\ttraining's multi_logloss: 0.989174\tvalid_1's multi_error: 0.475217\tvalid_1's multi_logloss: 1.07963\n",
      "[39]\ttraining's multi_error: 0.412302\ttraining's multi_logloss: 0.98654\tvalid_1's multi_error: 0.473978\tvalid_1's multi_logloss: 1.07896\n",
      "[40]\ttraining's multi_error: 0.410598\ttraining's multi_logloss: 0.984148\tvalid_1's multi_error: 0.469641\tvalid_1's multi_logloss: 1.07838\n",
      "[41]\ttraining's multi_error: 0.409359\ttraining's multi_logloss: 0.981898\tvalid_1's multi_error: 0.468401\tvalid_1's multi_logloss: 1.07784\n",
      "[42]\ttraining's multi_error: 0.409049\ttraining's multi_logloss: 0.979799\tvalid_1's multi_error: 0.47026\tvalid_1's multi_logloss: 1.07767\n",
      "[43]\ttraining's multi_error: 0.409823\ttraining's multi_logloss: 0.977613\tvalid_1's multi_error: 0.469021\tvalid_1's multi_logloss: 1.07717\n",
      "[44]\ttraining's multi_error: 0.409049\ttraining's multi_logloss: 0.975423\tvalid_1's multi_error: 0.467782\tvalid_1's multi_logloss: 1.07685\n",
      "[45]\ttraining's multi_error: 0.407499\ttraining's multi_logloss: 0.973195\tvalid_1's multi_error: 0.467782\tvalid_1's multi_logloss: 1.07645\n",
      "[46]\ttraining's multi_error: 0.40657\ttraining's multi_logloss: 0.971203\tvalid_1's multi_error: 0.467162\tvalid_1's multi_logloss: 1.07586\n",
      "[47]\ttraining's multi_error: 0.40564\ttraining's multi_logloss: 0.969161\tvalid_1's multi_error: 0.469641\tvalid_1's multi_logloss: 1.07531\n",
      "[48]\ttraining's multi_error: 0.4044\ttraining's multi_logloss: 0.967292\tvalid_1's multi_error: 0.467782\tvalid_1's multi_logloss: 1.07541\n",
      "[49]\ttraining's multi_error: 0.403781\ttraining's multi_logloss: 0.965259\tvalid_1's multi_error: 0.468401\tvalid_1's multi_logloss: 1.07535\n",
      "[50]\ttraining's multi_error: 0.402076\ttraining's multi_logloss: 0.963367\tvalid_1's multi_error: 0.467782\tvalid_1's multi_logloss: 1.07494\n",
      "[51]\ttraining's multi_error: 0.402696\ttraining's multi_logloss: 0.961614\tvalid_1's multi_error: 0.469021\tvalid_1's multi_logloss: 1.07506\n",
      "[52]\ttraining's multi_error: 0.402541\ttraining's multi_logloss: 0.959676\tvalid_1's multi_error: 0.472119\tvalid_1's multi_logloss: 1.07497\n",
      "[53]\ttraining's multi_error: 0.400992\ttraining's multi_logloss: 0.957995\tvalid_1's multi_error: 0.473358\tvalid_1's multi_logloss: 1.07507\n",
      "[54]\ttraining's multi_error: 0.400217\ttraining's multi_logloss: 0.956247\tvalid_1's multi_error: 0.472119\tvalid_1's multi_logloss: 1.07518\n",
      "[55]\ttraining's multi_error: 0.399442\ttraining's multi_logloss: 0.954506\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.07504\n",
      "[56]\ttraining's multi_error: 0.398358\ttraining's multi_logloss: 0.952909\tvalid_1's multi_error: 0.47088\tvalid_1's multi_logloss: 1.07515\n",
      "[57]\ttraining's multi_error: 0.397893\ttraining's multi_logloss: 0.951339\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.07527\n",
      "[58]\ttraining's multi_error: 0.397738\ttraining's multi_logloss: 0.949815\tvalid_1's multi_error: 0.474597\tvalid_1's multi_logloss: 1.07533\n",
      "[59]\ttraining's multi_error: 0.396653\ttraining's multi_logloss: 0.94821\tvalid_1's multi_error: 0.473978\tvalid_1's multi_logloss: 1.07522\n",
      "[60]\ttraining's multi_error: 0.396033\ttraining's multi_logloss: 0.94667\tvalid_1's multi_error: 0.474597\tvalid_1's multi_logloss: 1.07516\n",
      "[61]\ttraining's multi_error: 0.395724\ttraining's multi_logloss: 0.945423\tvalid_1's multi_error: 0.475836\tvalid_1's multi_logloss: 1.07558\n",
      "[62]\ttraining's multi_error: 0.396498\ttraining's multi_logloss: 0.943894\tvalid_1's multi_error: 0.477695\tvalid_1's multi_logloss: 1.07558\n",
      "[63]\ttraining's multi_error: 0.394174\ttraining's multi_logloss: 0.942459\tvalid_1's multi_error: 0.477076\tvalid_1's multi_logloss: 1.07554\n",
      "[64]\ttraining's multi_error: 0.393399\ttraining's multi_logloss: 0.941143\tvalid_1's multi_error: 0.475217\tvalid_1's multi_logloss: 1.07577\n",
      "[65]\ttraining's multi_error: 0.392315\ttraining's multi_logloss: 0.939818\tvalid_1's multi_error: 0.475836\tvalid_1's multi_logloss: 1.076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66]\ttraining's multi_error: 0.392935\ttraining's multi_logloss: 0.938491\tvalid_1's multi_error: 0.476456\tvalid_1's multi_logloss: 1.07611\n",
      "[67]\ttraining's multi_error: 0.39216\ttraining's multi_logloss: 0.937122\tvalid_1's multi_error: 0.477695\tvalid_1's multi_logloss: 1.07629\n",
      "[68]\ttraining's multi_error: 0.391695\ttraining's multi_logloss: 0.935612\tvalid_1's multi_error: 0.477695\tvalid_1's multi_logloss: 1.07633\n",
      "[69]\ttraining's multi_error: 0.390765\ttraining's multi_logloss: 0.934364\tvalid_1's multi_error: 0.474597\tvalid_1's multi_logloss: 1.0766\n",
      "[70]\ttraining's multi_error: 0.389681\ttraining's multi_logloss: 0.932993\tvalid_1's multi_error: 0.475217\tvalid_1's multi_logloss: 1.07677\n",
      "[71]\ttraining's multi_error: 0.389061\ttraining's multi_logloss: 0.931759\tvalid_1's multi_error: 0.477076\tvalid_1's multi_logloss: 1.07701\n",
      "[72]\ttraining's multi_error: 0.388131\ttraining's multi_logloss: 0.930355\tvalid_1's multi_error: 0.473978\tvalid_1's multi_logloss: 1.07718\n",
      "[73]\ttraining's multi_error: 0.387202\ttraining's multi_logloss: 0.928977\tvalid_1's multi_error: 0.474597\tvalid_1's multi_logloss: 1.07729\n",
      "[74]\ttraining's multi_error: 0.387357\ttraining's multi_logloss: 0.927698\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.07738\n",
      "[75]\ttraining's multi_error: 0.385962\ttraining's multi_logloss: 0.926468\tvalid_1's multi_error: 0.472739\tvalid_1's multi_logloss: 1.07764\n",
      "[76]\ttraining's multi_error: 0.386272\ttraining's multi_logloss: 0.925172\tvalid_1's multi_error: 0.475217\tvalid_1's multi_logloss: 1.07755\n",
      "[77]\ttraining's multi_error: 0.386272\ttraining's multi_logloss: 0.923954\tvalid_1's multi_error: 0.475836\tvalid_1's multi_logloss: 1.07767\n",
      "[78]\ttraining's multi_error: 0.386737\ttraining's multi_logloss: 0.922659\tvalid_1's multi_error: 0.476456\tvalid_1's multi_logloss: 1.07783\n",
      "[79]\ttraining's multi_error: 0.387202\ttraining's multi_logloss: 0.921475\tvalid_1's multi_error: 0.476456\tvalid_1's multi_logloss: 1.078\n",
      "[80]\ttraining's multi_error: 0.386427\ttraining's multi_logloss: 0.920302\tvalid_1's multi_error: 0.476456\tvalid_1's multi_logloss: 1.07844\n",
      "[81]\ttraining's multi_error: 0.385652\ttraining's multi_logloss: 0.919028\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.07881\n",
      "[82]\ttraining's multi_error: 0.385187\ttraining's multi_logloss: 0.917906\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.07912\n",
      "[83]\ttraining's multi_error: 0.384568\ttraining's multi_logloss: 0.916901\tvalid_1's multi_error: 0.477695\tvalid_1's multi_logloss: 1.07984\n",
      "[84]\ttraining's multi_error: 0.383328\ttraining's multi_logloss: 0.91576\tvalid_1's multi_error: 0.478315\tvalid_1's multi_logloss: 1.08019\n",
      "[85]\ttraining's multi_error: 0.383638\ttraining's multi_logloss: 0.914672\tvalid_1's multi_error: 0.479554\tvalid_1's multi_logloss: 1.08055\n",
      "[86]\ttraining's multi_error: 0.383173\ttraining's multi_logloss: 0.913482\tvalid_1's multi_error: 0.479554\tvalid_1's multi_logloss: 1.08038\n",
      "[87]\ttraining's multi_error: 0.381934\ttraining's multi_logloss: 0.912185\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.08053\n",
      "[88]\ttraining's multi_error: 0.382244\ttraining's multi_logloss: 0.911285\tvalid_1's multi_error: 0.478315\tvalid_1's multi_logloss: 1.08106\n",
      "[89]\ttraining's multi_error: 0.381159\ttraining's multi_logloss: 0.910363\tvalid_1's multi_error: 0.478315\tvalid_1's multi_logloss: 1.08115\n",
      "[90]\ttraining's multi_error: 0.380849\ttraining's multi_logloss: 0.909264\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.08125\n",
      "[91]\ttraining's multi_error: 0.380384\ttraining's multi_logloss: 0.908139\tvalid_1's multi_error: 0.480173\tvalid_1's multi_logloss: 1.0813\n",
      "[92]\ttraining's multi_error: 0.380384\ttraining's multi_logloss: 0.907145\tvalid_1's multi_error: 0.480793\tvalid_1's multi_logloss: 1.08156\n",
      "[93]\ttraining's multi_error: 0.379764\ttraining's multi_logloss: 0.906248\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.08175\n",
      "[94]\ttraining's multi_error: 0.37837\ttraining's multi_logloss: 0.905285\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.08196\n",
      "[95]\ttraining's multi_error: 0.378215\ttraining's multi_logloss: 0.904451\tvalid_1's multi_error: 0.480793\tvalid_1's multi_logloss: 1.08235\n",
      "[96]\ttraining's multi_error: 0.377905\ttraining's multi_logloss: 0.903458\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.08237\n",
      "[97]\ttraining's multi_error: 0.377285\ttraining's multi_logloss: 0.902613\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.08257\n",
      "[98]\ttraining's multi_error: 0.375426\ttraining's multi_logloss: 0.901825\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.08241\n",
      "[99]\ttraining's multi_error: 0.374961\ttraining's multi_logloss: 0.900928\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.08269\n",
      "[100]\ttraining's multi_error: 0.374032\ttraining's multi_logloss: 0.900041\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.08283\n",
      "[101]\ttraining's multi_error: 0.374032\ttraining's multi_logloss: 0.899017\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08292\n",
      "[102]\ttraining's multi_error: 0.372947\ttraining's multi_logloss: 0.898162\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.08277\n",
      "[103]\ttraining's multi_error: 0.372327\ttraining's multi_logloss: 0.897253\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.08298\n",
      "[104]\ttraining's multi_error: 0.371553\ttraining's multi_logloss: 0.895968\tvalid_1's multi_error: 0.480793\tvalid_1's multi_logloss: 1.0833\n",
      "[105]\ttraining's multi_error: 0.370933\ttraining's multi_logloss: 0.895022\tvalid_1's multi_error: 0.480173\tvalid_1's multi_logloss: 1.08361\n",
      "[106]\ttraining's multi_error: 0.372017\ttraining's multi_logloss: 0.89424\tvalid_1's multi_error: 0.480173\tvalid_1's multi_logloss: 1.08392\n",
      "[107]\ttraining's multi_error: 0.371553\ttraining's multi_logloss: 0.893322\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.08423\n",
      "[108]\ttraining's multi_error: 0.370933\ttraining's multi_logloss: 0.892586\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.08432\n",
      "[109]\ttraining's multi_error: 0.370778\ttraining's multi_logloss: 0.891916\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.08461\n",
      "[110]\ttraining's multi_error: 0.369848\ttraining's multi_logloss: 0.890961\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.08514\n",
      "[111]\ttraining's multi_error: 0.369848\ttraining's multi_logloss: 0.890113\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.08532\n",
      "[112]\ttraining's multi_error: 0.368919\ttraining's multi_logloss: 0.889262\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08583\n",
      "[113]\ttraining's multi_error: 0.369228\ttraining's multi_logloss: 0.888515\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.08612\n",
      "[114]\ttraining's multi_error: 0.369538\ttraining's multi_logloss: 0.887613\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.0865\n",
      "[115]\ttraining's multi_error: 0.368919\ttraining's multi_logloss: 0.886759\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.08706\n",
      "[116]\ttraining's multi_error: 0.368609\ttraining's multi_logloss: 0.88605\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.08751\n",
      "[117]\ttraining's multi_error: 0.368144\ttraining's multi_logloss: 0.885261\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08796\n",
      "[118]\ttraining's multi_error: 0.367989\ttraining's multi_logloss: 0.884708\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.08837\n",
      "[119]\ttraining's multi_error: 0.366904\ttraining's multi_logloss: 0.883817\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08864\n",
      "[120]\ttraining's multi_error: 0.367059\ttraining's multi_logloss: 0.883082\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.08861\n",
      "[121]\ttraining's multi_error: 0.366749\ttraining's multi_logloss: 0.8823\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08886\n",
      "[122]\ttraining's multi_error: 0.367214\ttraining's multi_logloss: 0.881511\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.08885\n",
      "[123]\ttraining's multi_error: 0.367679\ttraining's multi_logloss: 0.880902\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.0888\n",
      "[124]\ttraining's multi_error: 0.367059\ttraining's multi_logloss: 0.8801\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08908\n",
      "[125]\ttraining's multi_error: 0.367524\ttraining's multi_logloss: 0.879381\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.08913\n",
      "[126]\ttraining's multi_error: 0.366904\ttraining's multi_logloss: 0.878664\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.08929\n",
      "[127]\ttraining's multi_error: 0.366284\ttraining's multi_logloss: 0.877944\tvalid_1's multi_error: 0.482032\tvalid_1's multi_logloss: 1.0897\n",
      "[128]\ttraining's multi_error: 0.36613\ttraining's multi_logloss: 0.87727\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.0897\n",
      "[129]\ttraining's multi_error: 0.365355\ttraining's multi_logloss: 0.876543\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.08968\n",
      "[130]\ttraining's multi_error: 0.36489\ttraining's multi_logloss: 0.875897\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.09003\n",
      "[131]\ttraining's multi_error: 0.36427\ttraining's multi_logloss: 0.875258\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.0903\n",
      "[132]\ttraining's multi_error: 0.364115\ttraining's multi_logloss: 0.874548\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09053\n",
      "[133]\ttraining's multi_error: 0.365045\ttraining's multi_logloss: 0.873941\tvalid_1's multi_error: 0.480793\tvalid_1's multi_logloss: 1.09061\n",
      "[134]\ttraining's multi_error: 0.365045\ttraining's multi_logloss: 0.873335\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.09066\n",
      "[135]\ttraining's multi_error: 0.364425\ttraining's multi_logloss: 0.872873\tvalid_1's multi_error: 0.478934\tvalid_1's multi_logloss: 1.09079\n",
      "[136]\ttraining's multi_error: 0.36365\ttraining's multi_logloss: 0.872418\tvalid_1's multi_error: 0.480793\tvalid_1's multi_logloss: 1.09113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137]\ttraining's multi_error: 0.36365\ttraining's multi_logloss: 0.871725\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09142\n",
      "[138]\ttraining's multi_error: 0.363341\ttraining's multi_logloss: 0.871079\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09169\n",
      "[139]\ttraining's multi_error: 0.362256\ttraining's multi_logloss: 0.870348\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09217\n",
      "[140]\ttraining's multi_error: 0.362876\ttraining's multi_logloss: 0.86978\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.09247\n",
      "[141]\ttraining's multi_error: 0.362256\ttraining's multi_logloss: 0.869113\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09277\n",
      "[142]\ttraining's multi_error: 0.361791\ttraining's multi_logloss: 0.868396\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09305\n",
      "[143]\ttraining's multi_error: 0.361791\ttraining's multi_logloss: 0.867744\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09312\n",
      "[144]\ttraining's multi_error: 0.361791\ttraining's multi_logloss: 0.866995\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.09334\n",
      "[145]\ttraining's multi_error: 0.361481\ttraining's multi_logloss: 0.866306\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09361\n",
      "[146]\ttraining's multi_error: 0.360707\ttraining's multi_logloss: 0.865662\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.09388\n",
      "[147]\ttraining's multi_error: 0.360861\ttraining's multi_logloss: 0.8649\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.09431\n",
      "[148]\ttraining's multi_error: 0.360552\ttraining's multi_logloss: 0.864255\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.09464\n",
      "[149]\ttraining's multi_error: 0.360242\ttraining's multi_logloss: 0.863537\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.09529\n",
      "[150]\ttraining's multi_error: 0.359777\ttraining's multi_logloss: 0.863003\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.09558\n",
      "[151]\ttraining's multi_error: 0.358382\ttraining's multi_logloss: 0.862513\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09569\n",
      "[152]\ttraining's multi_error: 0.357763\ttraining's multi_logloss: 0.861972\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09585\n",
      "[153]\ttraining's multi_error: 0.356058\ttraining's multi_logloss: 0.861437\tvalid_1's multi_error: 0.481413\tvalid_1's multi_logloss: 1.096\n",
      "[154]\ttraining's multi_error: 0.356213\ttraining's multi_logloss: 0.861034\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09626\n",
      "[155]\ttraining's multi_error: 0.355748\ttraining's multi_logloss: 0.860529\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.09646\n",
      "[156]\ttraining's multi_error: 0.356213\ttraining's multi_logloss: 0.860027\tvalid_1's multi_error: 0.482652\tvalid_1's multi_logloss: 1.0967\n",
      "[157]\ttraining's multi_error: 0.356213\ttraining's multi_logloss: 0.859531\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.097\n",
      "[158]\ttraining's multi_error: 0.355438\ttraining's multi_logloss: 0.859059\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.09725\n",
      "[159]\ttraining's multi_error: 0.355903\ttraining's multi_logloss: 0.858526\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09752\n",
      "[160]\ttraining's multi_error: 0.354974\ttraining's multi_logloss: 0.858024\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09782\n",
      "[161]\ttraining's multi_error: 0.354044\ttraining's multi_logloss: 0.857541\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.09816\n",
      "[162]\ttraining's multi_error: 0.353114\ttraining's multi_logloss: 0.856922\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.09843\n",
      "[163]\ttraining's multi_error: 0.35234\ttraining's multi_logloss: 0.85632\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.09861\n",
      "[164]\ttraining's multi_error: 0.35234\ttraining's multi_logloss: 0.855664\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.09912\n",
      "[165]\ttraining's multi_error: 0.35203\ttraining's multi_logloss: 0.85514\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.09938\n",
      "[166]\ttraining's multi_error: 0.35172\ttraining's multi_logloss: 0.854465\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.09981\n",
      "[167]\ttraining's multi_error: 0.35141\ttraining's multi_logloss: 0.854007\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10005\n",
      "[168]\ttraining's multi_error: 0.350635\ttraining's multi_logloss: 0.853315\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10028\n",
      "[169]\ttraining's multi_error: 0.350325\ttraining's multi_logloss: 0.852752\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.10058\n",
      "[170]\ttraining's multi_error: 0.35017\ttraining's multi_logloss: 0.852195\tvalid_1's multi_error: 0.486989\tvalid_1's multi_logloss: 1.10082\n",
      "[171]\ttraining's multi_error: 0.349241\ttraining's multi_logloss: 0.851642\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.10103\n",
      "[172]\ttraining's multi_error: 0.349241\ttraining's multi_logloss: 0.851124\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10118\n",
      "[173]\ttraining's multi_error: 0.349086\ttraining's multi_logloss: 0.850612\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10131\n",
      "[174]\ttraining's multi_error: 0.348776\ttraining's multi_logloss: 0.850089\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.10149\n",
      "[175]\ttraining's multi_error: 0.348466\ttraining's multi_logloss: 0.849545\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10198\n",
      "[176]\ttraining's multi_error: 0.347072\ttraining's multi_logloss: 0.849091\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10229\n",
      "[177]\ttraining's multi_error: 0.346762\ttraining's multi_logloss: 0.848641\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10241\n",
      "[178]\ttraining's multi_error: 0.346142\ttraining's multi_logloss: 0.848207\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10263\n",
      "[179]\ttraining's multi_error: 0.346607\ttraining's multi_logloss: 0.847758\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10288\n",
      "[180]\ttraining's multi_error: 0.346607\ttraining's multi_logloss: 0.847122\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10301\n",
      "[181]\ttraining's multi_error: 0.345987\ttraining's multi_logloss: 0.846726\tvalid_1's multi_error: 0.486989\tvalid_1's multi_logloss: 1.10318\n",
      "[182]\ttraining's multi_error: 0.345832\ttraining's multi_logloss: 0.846071\tvalid_1's multi_error: 0.486989\tvalid_1's multi_logloss: 1.10326\n",
      "[183]\ttraining's multi_error: 0.345832\ttraining's multi_logloss: 0.845636\tvalid_1's multi_error: 0.486989\tvalid_1's multi_logloss: 1.10332\n",
      "[184]\ttraining's multi_error: 0.344902\ttraining's multi_logloss: 0.845208\tvalid_1's multi_error: 0.486989\tvalid_1's multi_logloss: 1.10346\n",
      "[185]\ttraining's multi_error: 0.344747\ttraining's multi_logloss: 0.844772\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10375\n",
      "[186]\ttraining's multi_error: 0.344593\ttraining's multi_logloss: 0.844312\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10402\n",
      "[187]\ttraining's multi_error: 0.344438\ttraining's multi_logloss: 0.843869\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10424\n",
      "[188]\ttraining's multi_error: 0.344593\ttraining's multi_logloss: 0.843337\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.10444\n",
      "[189]\ttraining's multi_error: 0.344283\ttraining's multi_logloss: 0.84296\tvalid_1's multi_error: 0.483891\tvalid_1's multi_logloss: 1.10465\n",
      "[190]\ttraining's multi_error: 0.344128\ttraining's multi_logloss: 0.842579\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.10478\n",
      "[191]\ttraining's multi_error: 0.343973\ttraining's multi_logloss: 0.842056\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10495\n",
      "[192]\ttraining's multi_error: 0.342733\ttraining's multi_logloss: 0.841449\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10502\n",
      "[193]\ttraining's multi_error: 0.343353\ttraining's multi_logloss: 0.841022\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10532\n",
      "[194]\ttraining's multi_error: 0.343198\ttraining's multi_logloss: 0.84052\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10556\n",
      "[195]\ttraining's multi_error: 0.343508\ttraining's multi_logloss: 0.839871\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10583\n",
      "[196]\ttraining's multi_error: 0.343198\ttraining's multi_logloss: 0.839314\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10607\n",
      "[197]\ttraining's multi_error: 0.342423\ttraining's multi_logloss: 0.838742\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10602\n",
      "[198]\ttraining's multi_error: 0.342113\ttraining's multi_logloss: 0.838157\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10629\n",
      "[199]\ttraining's multi_error: 0.340564\ttraining's multi_logloss: 0.837388\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.10637\n",
      "[200]\ttraining's multi_error: 0.340719\ttraining's multi_logloss: 0.836951\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10654\n",
      "[201]\ttraining's multi_error: 0.340564\ttraining's multi_logloss: 0.836628\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10669\n",
      "[202]\ttraining's multi_error: 0.339324\ttraining's multi_logloss: 0.836115\tvalid_1's multi_error: 0.486369\tvalid_1's multi_logloss: 1.10698\n",
      "[203]\ttraining's multi_error: 0.339015\ttraining's multi_logloss: 0.835709\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.1072\n",
      "[204]\ttraining's multi_error: 0.33855\ttraining's multi_logloss: 0.835367\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.1073\n",
      "[205]\ttraining's multi_error: 0.33886\ttraining's multi_logloss: 0.834735\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10738\n",
      "[206]\ttraining's multi_error: 0.33917\ttraining's multi_logloss: 0.834378\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.10759\n",
      "[207]\ttraining's multi_error: 0.338705\ttraining's multi_logloss: 0.834045\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10763\n",
      "[208]\ttraining's multi_error: 0.338395\ttraining's multi_logloss: 0.833555\tvalid_1's multi_error: 0.483271\tvalid_1's multi_logloss: 1.10766\n",
      "[209]\ttraining's multi_error: 0.338395\ttraining's multi_logloss: 0.833183\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[210]\ttraining's multi_error: 0.33793\ttraining's multi_logloss: 0.832791\tvalid_1's multi_error: 0.484511\tvalid_1's multi_logloss: 1.10813\n",
      "[211]\ttraining's multi_error: 0.338085\ttraining's multi_logloss: 0.832365\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10847\n",
      "[212]\ttraining's multi_error: 0.33855\ttraining's multi_logloss: 0.832004\tvalid_1's multi_error: 0.48513\tvalid_1's multi_logloss: 1.10878\n",
      "[213]\ttraining's multi_error: 0.33886\ttraining's multi_logloss: 0.831518\tvalid_1's multi_error: 0.48575\tvalid_1's multi_logloss: 1.10903\n",
      "[214]\ttraining's multi_error: 0.33886\ttraining's multi_logloss: 0.831016\tvalid_1's multi_error: 0.487608\tvalid_1's multi_logloss: 1.10926\n",
      "[215]\ttraining's multi_error: 0.337775\ttraining's multi_logloss: 0.830494\tvalid_1's multi_error: 0.488228\tvalid_1's multi_logloss: 1.10958\n",
      "[216]\ttraining's multi_error: 0.337465\ttraining's multi_logloss: 0.83003\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.10982\n",
      "[217]\ttraining's multi_error: 0.33731\ttraining's multi_logloss: 0.829574\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11017\n",
      "[218]\ttraining's multi_error: 0.337775\ttraining's multi_logloss: 0.82917\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11042\n",
      "[219]\ttraining's multi_error: 0.33762\ttraining's multi_logloss: 0.828798\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11054\n",
      "[220]\ttraining's multi_error: 0.337155\ttraining's multi_logloss: 0.828352\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11053\n",
      "[221]\ttraining's multi_error: 0.336071\ttraining's multi_logloss: 0.827857\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11076\n",
      "[222]\ttraining's multi_error: 0.335296\ttraining's multi_logloss: 0.82747\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11087\n",
      "[223]\ttraining's multi_error: 0.334521\ttraining's multi_logloss: 0.827183\tvalid_1's multi_error: 0.491945\tvalid_1's multi_logloss: 1.11089\n",
      "[224]\ttraining's multi_error: 0.335141\ttraining's multi_logloss: 0.826839\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.11105\n",
      "[225]\ttraining's multi_error: 0.334986\ttraining's multi_logloss: 0.826484\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11124\n",
      "[226]\ttraining's multi_error: 0.334366\ttraining's multi_logloss: 0.825976\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11144\n",
      "[227]\ttraining's multi_error: 0.334521\ttraining's multi_logloss: 0.825648\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11162\n",
      "[228]\ttraining's multi_error: 0.333747\ttraining's multi_logloss: 0.825322\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11185\n",
      "[229]\ttraining's multi_error: 0.333747\ttraining's multi_logloss: 0.824862\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11204\n",
      "[230]\ttraining's multi_error: 0.334056\ttraining's multi_logloss: 0.824552\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11236\n",
      "[231]\ttraining's multi_error: 0.333127\ttraining's multi_logloss: 0.824194\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11264\n",
      "[232]\ttraining's multi_error: 0.331732\ttraining's multi_logloss: 0.823822\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11299\n",
      "[233]\ttraining's multi_error: 0.332507\ttraining's multi_logloss: 0.823409\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.1133\n",
      "[234]\ttraining's multi_error: 0.332042\ttraining's multi_logloss: 0.822995\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.1135\n",
      "[235]\ttraining's multi_error: 0.331112\ttraining's multi_logloss: 0.822652\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11355\n",
      "[236]\ttraining's multi_error: 0.330958\ttraining's multi_logloss: 0.8222\tvalid_1's multi_error: 0.488848\tvalid_1's multi_logloss: 1.11381\n",
      "[237]\ttraining's multi_error: 0.330958\ttraining's multi_logloss: 0.821754\tvalid_1's multi_error: 0.488228\tvalid_1's multi_logloss: 1.11379\n",
      "[238]\ttraining's multi_error: 0.331577\ttraining's multi_logloss: 0.821392\tvalid_1's multi_error: 0.487608\tvalid_1's multi_logloss: 1.11391\n",
      "[239]\ttraining's multi_error: 0.331577\ttraining's multi_logloss: 0.820892\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11396\n",
      "[240]\ttraining's multi_error: 0.331112\ttraining's multi_logloss: 0.820543\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11415\n",
      "[241]\ttraining's multi_error: 0.330648\ttraining's multi_logloss: 0.820167\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11428\n",
      "[242]\ttraining's multi_error: 0.330958\ttraining's multi_logloss: 0.819835\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.1145\n",
      "[243]\ttraining's multi_error: 0.331267\ttraining's multi_logloss: 0.819453\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11469\n",
      "[244]\ttraining's multi_error: 0.330648\ttraining's multi_logloss: 0.819097\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11461\n",
      "[245]\ttraining's multi_error: 0.330338\ttraining's multi_logloss: 0.818763\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11468\n",
      "[246]\ttraining's multi_error: 0.330493\ttraining's multi_logloss: 0.818304\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11465\n",
      "[247]\ttraining's multi_error: 0.330183\ttraining's multi_logloss: 0.817897\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11482\n",
      "[248]\ttraining's multi_error: 0.329873\ttraining's multi_logloss: 0.81765\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11499\n",
      "[249]\ttraining's multi_error: 0.329873\ttraining's multi_logloss: 0.817376\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.1152\n",
      "[250]\ttraining's multi_error: 0.329873\ttraining's multi_logloss: 0.817017\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11533\n",
      "[251]\ttraining's multi_error: 0.329718\ttraining's multi_logloss: 0.816761\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11549\n",
      "[252]\ttraining's multi_error: 0.329253\ttraining's multi_logloss: 0.816415\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11566\n",
      "[253]\ttraining's multi_error: 0.329563\ttraining's multi_logloss: 0.816114\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11578\n",
      "[254]\ttraining's multi_error: 0.328943\ttraining's multi_logloss: 0.81584\tvalid_1's multi_error: 0.489467\tvalid_1's multi_logloss: 1.11605\n",
      "[255]\ttraining's multi_error: 0.328478\ttraining's multi_logloss: 0.815561\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11626\n",
      "[256]\ttraining's multi_error: 0.328788\ttraining's multi_logloss: 0.815312\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11636\n",
      "[257]\ttraining's multi_error: 0.328633\ttraining's multi_logloss: 0.81511\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11648\n",
      "[258]\ttraining's multi_error: 0.328169\ttraining's multi_logloss: 0.814764\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11671\n",
      "[259]\ttraining's multi_error: 0.327704\ttraining's multi_logloss: 0.814538\tvalid_1's multi_error: 0.491945\tvalid_1's multi_logloss: 1.11685\n",
      "[260]\ttraining's multi_error: 0.327859\ttraining's multi_logloss: 0.814261\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11688\n",
      "[261]\ttraining's multi_error: 0.327239\ttraining's multi_logloss: 0.8139\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11701\n",
      "[262]\ttraining's multi_error: 0.326619\ttraining's multi_logloss: 0.813498\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11692\n",
      "[263]\ttraining's multi_error: 0.326464\ttraining's multi_logloss: 0.81308\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11704\n",
      "[264]\ttraining's multi_error: 0.326774\ttraining's multi_logloss: 0.812823\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11717\n",
      "[265]\ttraining's multi_error: 0.325999\ttraining's multi_logloss: 0.812535\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11746\n",
      "[266]\ttraining's multi_error: 0.325844\ttraining's multi_logloss: 0.812269\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.1177\n",
      "[267]\ttraining's multi_error: 0.325535\ttraining's multi_logloss: 0.811901\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11774\n",
      "[268]\ttraining's multi_error: 0.32507\ttraining's multi_logloss: 0.811685\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11794\n",
      "[269]\ttraining's multi_error: 0.32507\ttraining's multi_logloss: 0.811442\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11811\n",
      "[270]\ttraining's multi_error: 0.324915\ttraining's multi_logloss: 0.811142\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11829\n",
      "[271]\ttraining's multi_error: 0.32476\ttraining's multi_logloss: 0.810884\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11837\n",
      "[272]\ttraining's multi_error: 0.324915\ttraining's multi_logloss: 0.81067\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11841\n",
      "[273]\ttraining's multi_error: 0.325689\ttraining's multi_logloss: 0.810481\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11865\n",
      "[274]\ttraining's multi_error: 0.325844\ttraining's multi_logloss: 0.810329\tvalid_1's multi_error: 0.490087\tvalid_1's multi_logloss: 1.11882\n",
      "[275]\ttraining's multi_error: 0.325689\ttraining's multi_logloss: 0.810155\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11898\n",
      "[276]\ttraining's multi_error: 0.325844\ttraining's multi_logloss: 0.810011\tvalid_1's multi_error: 0.490706\tvalid_1's multi_logloss: 1.11913\n",
      "[277]\ttraining's multi_error: 0.325689\ttraining's multi_logloss: 0.809804\tvalid_1's multi_error: 0.491326\tvalid_1's multi_logloss: 1.11928\n",
      "[278]\ttraining's multi_error: 0.324915\ttraining's multi_logloss: 0.809621\tvalid_1's multi_error: 0.491945\tvalid_1's multi_logloss: 1.1195\n",
      "[279]\ttraining's multi_error: 0.324605\ttraining's multi_logloss: 0.809454\tvalid_1's multi_error: 0.491945\tvalid_1's multi_logloss: 1.11963\n",
      "[280]\ttraining's multi_error: 0.323985\ttraining's multi_logloss: 0.809261\tvalid_1's multi_error: 0.491945\tvalid_1's multi_logloss: 1.11965\n",
      "[281]\ttraining's multi_error: 0.32445\ttraining's multi_logloss: 0.809063\tvalid_1's multi_error: 0.492565\tvalid_1's multi_logloss: 1.1198\n",
      "[282]\ttraining's multi_error: 0.32507\ttraining's multi_logloss: 0.808877\tvalid_1's multi_error: 0.492565\tvalid_1's multi_logloss: 1.11986\n",
      "[283]\ttraining's multi_error: 0.32445\ttraining's multi_logloss: 0.808761\tvalid_1's multi_error: 0.492565\tvalid_1's multi_logloss: 1.11994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284]\ttraining's multi_error: 0.323985\ttraining's multi_logloss: 0.808579\tvalid_1's multi_error: 0.492565\tvalid_1's multi_logloss: 1.12002\n",
      "[285]\ttraining's multi_error: 0.32445\ttraining's multi_logloss: 0.808378\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.11996\n",
      "[286]\ttraining's multi_error: 0.323985\ttraining's multi_logloss: 0.808216\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.11995\n",
      "[287]\ttraining's multi_error: 0.32383\ttraining's multi_logloss: 0.808078\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.12006\n",
      "[288]\ttraining's multi_error: 0.323985\ttraining's multi_logloss: 0.80784\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.11994\n",
      "[289]\ttraining's multi_error: 0.32352\ttraining's multi_logloss: 0.807601\tvalid_1's multi_error: 0.492565\tvalid_1's multi_logloss: 1.12008\n",
      "[290]\ttraining's multi_error: 0.322901\ttraining's multi_logloss: 0.807362\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.12006\n",
      "[291]\ttraining's multi_error: 0.323365\ttraining's multi_logloss: 0.807185\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.12024\n",
      "[292]\ttraining's multi_error: 0.32352\ttraining's multi_logloss: 0.807027\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.12043\n",
      "[293]\ttraining's multi_error: 0.322436\ttraining's multi_logloss: 0.806684\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.12061\n",
      "[294]\ttraining's multi_error: 0.322591\ttraining's multi_logloss: 0.806324\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.12084\n",
      "[295]\ttraining's multi_error: 0.322746\ttraining's multi_logloss: 0.805891\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.12102\n",
      "[296]\ttraining's multi_error: 0.32383\ttraining's multi_logloss: 0.805621\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.1212\n",
      "[297]\ttraining's multi_error: 0.32383\ttraining's multi_logloss: 0.805403\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.12127\n",
      "[298]\ttraining's multi_error: 0.32352\ttraining's multi_logloss: 0.805193\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.1214\n",
      "[299]\ttraining's multi_error: 0.32352\ttraining's multi_logloss: 0.80495\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12143\n",
      "[300]\ttraining's multi_error: 0.32321\ttraining's multi_logloss: 0.804773\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12152\n",
      "[301]\ttraining's multi_error: 0.322746\ttraining's multi_logloss: 0.804538\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12171\n",
      "[302]\ttraining's multi_error: 0.322901\ttraining's multi_logloss: 0.804311\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12177\n",
      "[303]\ttraining's multi_error: 0.322901\ttraining's multi_logloss: 0.804088\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12189\n",
      "[304]\ttraining's multi_error: 0.322281\ttraining's multi_logloss: 0.803941\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12197\n",
      "[305]\ttraining's multi_error: 0.322436\ttraining's multi_logloss: 0.80374\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12208\n",
      "[306]\ttraining's multi_error: 0.323055\ttraining's multi_logloss: 0.803484\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12226\n",
      "[307]\ttraining's multi_error: 0.32321\ttraining's multi_logloss: 0.803257\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12232\n",
      "[308]\ttraining's multi_error: 0.32383\ttraining's multi_logloss: 0.803095\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12251\n",
      "[309]\ttraining's multi_error: 0.323055\ttraining's multi_logloss: 0.80292\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12258\n",
      "[310]\ttraining's multi_error: 0.322746\ttraining's multi_logloss: 0.802605\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12272\n",
      "[311]\ttraining's multi_error: 0.323055\ttraining's multi_logloss: 0.802303\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12288\n",
      "[312]\ttraining's multi_error: 0.32321\ttraining's multi_logloss: 0.802023\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12316\n",
      "[313]\ttraining's multi_error: 0.323055\ttraining's multi_logloss: 0.801755\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.12317\n",
      "[314]\ttraining's multi_error: 0.322901\ttraining's multi_logloss: 0.801528\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12325\n",
      "[315]\ttraining's multi_error: 0.322746\ttraining's multi_logloss: 0.801327\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.1234\n",
      "[316]\ttraining's multi_error: 0.322746\ttraining's multi_logloss: 0.801236\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12351\n",
      "[317]\ttraining's multi_error: 0.322591\ttraining's multi_logloss: 0.801075\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12354\n",
      "[318]\ttraining's multi_error: 0.322746\ttraining's multi_logloss: 0.800847\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.1236\n",
      "[319]\ttraining's multi_error: 0.322591\ttraining's multi_logloss: 0.800526\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.1236\n",
      "[320]\ttraining's multi_error: 0.322591\ttraining's multi_logloss: 0.800183\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12378\n",
      "[321]\ttraining's multi_error: 0.322281\ttraining's multi_logloss: 0.799932\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12383\n",
      "[322]\ttraining's multi_error: 0.322281\ttraining's multi_logloss: 0.799633\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12388\n",
      "[323]\ttraining's multi_error: 0.321816\ttraining's multi_logloss: 0.79938\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.12391\n",
      "[324]\ttraining's multi_error: 0.322126\ttraining's multi_logloss: 0.799156\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.1239\n",
      "[325]\ttraining's multi_error: 0.322281\ttraining's multi_logloss: 0.798941\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12403\n",
      "[326]\ttraining's multi_error: 0.321971\ttraining's multi_logloss: 0.798728\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12408\n",
      "[327]\ttraining's multi_error: 0.321661\ttraining's multi_logloss: 0.79831\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12417\n",
      "[328]\ttraining's multi_error: 0.321196\ttraining's multi_logloss: 0.79788\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12425\n",
      "[329]\ttraining's multi_error: 0.320576\ttraining's multi_logloss: 0.79767\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12428\n",
      "[330]\ttraining's multi_error: 0.319957\ttraining's multi_logloss: 0.797557\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12432\n",
      "[331]\ttraining's multi_error: 0.319647\ttraining's multi_logloss: 0.797299\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12448\n",
      "[332]\ttraining's multi_error: 0.319027\ttraining's multi_logloss: 0.79698\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12455\n",
      "[333]\ttraining's multi_error: 0.318872\ttraining's multi_logloss: 0.796732\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.1246\n",
      "[334]\ttraining's multi_error: 0.319182\ttraining's multi_logloss: 0.796491\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.12461\n",
      "[335]\ttraining's multi_error: 0.319957\ttraining's multi_logloss: 0.796266\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12471\n",
      "[336]\ttraining's multi_error: 0.319182\ttraining's multi_logloss: 0.796103\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12477\n",
      "[337]\ttraining's multi_error: 0.319027\ttraining's multi_logloss: 0.795907\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12495\n",
      "[338]\ttraining's multi_error: 0.318407\ttraining's multi_logloss: 0.795719\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12501\n",
      "[339]\ttraining's multi_error: 0.318407\ttraining's multi_logloss: 0.795405\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12509\n",
      "[340]\ttraining's multi_error: 0.317942\ttraining's multi_logloss: 0.794952\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12519\n",
      "[341]\ttraining's multi_error: 0.318407\ttraining's multi_logloss: 0.794617\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12528\n",
      "[342]\ttraining's multi_error: 0.318717\ttraining's multi_logloss: 0.794241\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12543\n",
      "[343]\ttraining's multi_error: 0.319027\ttraining's multi_logloss: 0.793917\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12563\n",
      "[344]\ttraining's multi_error: 0.318097\ttraining's multi_logloss: 0.793499\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12591\n",
      "[345]\ttraining's multi_error: 0.318252\ttraining's multi_logloss: 0.793062\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.12604\n",
      "[346]\ttraining's multi_error: 0.316858\ttraining's multi_logloss: 0.792608\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.12623\n",
      "[347]\ttraining's multi_error: 0.316238\ttraining's multi_logloss: 0.792275\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12628\n",
      "[348]\ttraining's multi_error: 0.315928\ttraining's multi_logloss: 0.79181\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12624\n",
      "[349]\ttraining's multi_error: 0.315928\ttraining's multi_logloss: 0.791457\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.12622\n",
      "[350]\ttraining's multi_error: 0.315463\ttraining's multi_logloss: 0.791197\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12633\n",
      "[351]\ttraining's multi_error: 0.315463\ttraining's multi_logloss: 0.790862\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12659\n",
      "[352]\ttraining's multi_error: 0.315618\ttraining's multi_logloss: 0.790524\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12678\n",
      "[353]\ttraining's multi_error: 0.315618\ttraining's multi_logloss: 0.790235\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12695\n",
      "[354]\ttraining's multi_error: 0.315928\ttraining's multi_logloss: 0.789925\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12703\n",
      "[355]\ttraining's multi_error: 0.314998\ttraining's multi_logloss: 0.789595\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12731\n",
      "[356]\ttraining's multi_error: 0.315308\ttraining's multi_logloss: 0.789342\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[357]\ttraining's multi_error: 0.315928\ttraining's multi_logloss: 0.789161\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12755\n",
      "[358]\ttraining's multi_error: 0.315463\ttraining's multi_logloss: 0.788914\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12773\n",
      "[359]\ttraining's multi_error: 0.315153\ttraining's multi_logloss: 0.788709\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.12794\n",
      "[360]\ttraining's multi_error: 0.314534\ttraining's multi_logloss: 0.788456\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12799\n",
      "[361]\ttraining's multi_error: 0.314379\ttraining's multi_logloss: 0.788256\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12817\n",
      "[362]\ttraining's multi_error: 0.314534\ttraining's multi_logloss: 0.788048\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.12834\n",
      "[363]\ttraining's multi_error: 0.314224\ttraining's multi_logloss: 0.787867\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.12841\n",
      "[364]\ttraining's multi_error: 0.314534\ttraining's multi_logloss: 0.787719\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.12848\n",
      "[365]\ttraining's multi_error: 0.314224\ttraining's multi_logloss: 0.787437\tvalid_1's multi_error: 0.501239\tvalid_1's multi_logloss: 1.12864\n",
      "[366]\ttraining's multi_error: 0.314534\ttraining's multi_logloss: 0.787296\tvalid_1's multi_error: 0.501239\tvalid_1's multi_logloss: 1.12873\n",
      "[367]\ttraining's multi_error: 0.314689\ttraining's multi_logloss: 0.787085\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.12886\n",
      "[368]\ttraining's multi_error: 0.314224\ttraining's multi_logloss: 0.786861\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.12902\n",
      "[369]\ttraining's multi_error: 0.314844\ttraining's multi_logloss: 0.786607\tvalid_1's multi_error: 0.502478\tvalid_1's multi_logloss: 1.12923\n",
      "[370]\ttraining's multi_error: 0.314069\ttraining's multi_logloss: 0.786404\tvalid_1's multi_error: 0.501239\tvalid_1's multi_logloss: 1.12928\n",
      "[371]\ttraining's multi_error: 0.314379\ttraining's multi_logloss: 0.786122\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.1294\n",
      "[372]\ttraining's multi_error: 0.314379\ttraining's multi_logloss: 0.785934\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.12948\n",
      "[373]\ttraining's multi_error: 0.314534\ttraining's multi_logloss: 0.785755\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12955\n",
      "[374]\ttraining's multi_error: 0.314069\ttraining's multi_logloss: 0.785516\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.12967\n",
      "[375]\ttraining's multi_error: 0.313139\ttraining's multi_logloss: 0.785273\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12974\n",
      "[376]\ttraining's multi_error: 0.312055\ttraining's multi_logloss: 0.785031\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.12979\n",
      "[377]\ttraining's multi_error: 0.312519\ttraining's multi_logloss: 0.784819\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.12991\n",
      "[378]\ttraining's multi_error: 0.312364\ttraining's multi_logloss: 0.784676\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.13007\n",
      "[379]\ttraining's multi_error: 0.312209\ttraining's multi_logloss: 0.784529\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.13026\n",
      "[380]\ttraining's multi_error: 0.312364\ttraining's multi_logloss: 0.78435\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.13036\n",
      "[381]\ttraining's multi_error: 0.312209\ttraining's multi_logloss: 0.784206\tvalid_1's multi_error: 0.50062\tvalid_1's multi_logloss: 1.13054\n",
      "[382]\ttraining's multi_error: 0.3119\ttraining's multi_logloss: 0.78406\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.13067\n",
      "[383]\ttraining's multi_error: 0.3119\ttraining's multi_logloss: 0.783957\tvalid_1's multi_error: 0.5\tvalid_1's multi_logloss: 1.13081\n",
      "[384]\ttraining's multi_error: 0.311125\ttraining's multi_logloss: 0.783742\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.1309\n",
      "[385]\ttraining's multi_error: 0.31128\ttraining's multi_logloss: 0.783577\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.13103\n",
      "[386]\ttraining's multi_error: 0.31097\ttraining's multi_logloss: 0.78338\tvalid_1's multi_error: 0.49938\tvalid_1's multi_logloss: 1.13112\n",
      "[387]\ttraining's multi_error: 0.31128\ttraining's multi_logloss: 0.783167\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13114\n",
      "[388]\ttraining's multi_error: 0.31097\ttraining's multi_logloss: 0.782988\tvalid_1's multi_error: 0.498761\tvalid_1's multi_logloss: 1.13123\n",
      "[389]\ttraining's multi_error: 0.311125\ttraining's multi_logloss: 0.782789\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13124\n",
      "[390]\ttraining's multi_error: 0.311125\ttraining's multi_logloss: 0.78258\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.1315\n",
      "[391]\ttraining's multi_error: 0.31097\ttraining's multi_logloss: 0.782444\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13152\n",
      "[392]\ttraining's multi_error: 0.311125\ttraining's multi_logloss: 0.782209\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13169\n",
      "[393]\ttraining's multi_error: 0.310815\ttraining's multi_logloss: 0.782005\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13173\n",
      "[394]\ttraining's multi_error: 0.31066\ttraining's multi_logloss: 0.781796\tvalid_1's multi_error: 0.498141\tvalid_1's multi_logloss: 1.13195\n",
      "[395]\ttraining's multi_error: 0.31035\ttraining's multi_logloss: 0.781436\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13209\n",
      "[396]\ttraining's multi_error: 0.310505\ttraining's multi_logloss: 0.781314\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13218\n",
      "[397]\ttraining's multi_error: 0.31035\ttraining's multi_logloss: 0.781027\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13223\n",
      "[398]\ttraining's multi_error: 0.31035\ttraining's multi_logloss: 0.780892\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13227\n",
      "[399]\ttraining's multi_error: 0.310505\ttraining's multi_logloss: 0.780669\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13247\n",
      "[400]\ttraining's multi_error: 0.31035\ttraining's multi_logloss: 0.780563\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13251\n",
      "[401]\ttraining's multi_error: 0.310815\ttraining's multi_logloss: 0.780388\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13261\n",
      "[402]\ttraining's multi_error: 0.31097\ttraining's multi_logloss: 0.780293\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13272\n",
      "[403]\ttraining's multi_error: 0.31097\ttraining's multi_logloss: 0.780201\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13277\n",
      "[404]\ttraining's multi_error: 0.310505\ttraining's multi_logloss: 0.780046\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13284\n",
      "[405]\ttraining's multi_error: 0.310195\ttraining's multi_logloss: 0.779928\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13286\n",
      "[406]\ttraining's multi_error: 0.310195\ttraining's multi_logloss: 0.779783\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13304\n",
      "[407]\ttraining's multi_error: 0.31035\ttraining's multi_logloss: 0.779606\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13315\n",
      "[408]\ttraining's multi_error: 0.31066\ttraining's multi_logloss: 0.779468\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13327\n",
      "[409]\ttraining's multi_error: 0.31004\ttraining's multi_logloss: 0.779298\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13351\n",
      "[410]\ttraining's multi_error: 0.309575\ttraining's multi_logloss: 0.779122\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13372\n",
      "[411]\ttraining's multi_error: 0.309421\ttraining's multi_logloss: 0.779001\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13383\n",
      "[412]\ttraining's multi_error: 0.308956\ttraining's multi_logloss: 0.77878\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13399\n",
      "[413]\ttraining's multi_error: 0.308801\ttraining's multi_logloss: 0.778519\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13417\n",
      "[414]\ttraining's multi_error: 0.308956\ttraining's multi_logloss: 0.77839\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13432\n",
      "[415]\ttraining's multi_error: 0.309885\ttraining's multi_logloss: 0.778258\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13446\n",
      "[416]\ttraining's multi_error: 0.30973\ttraining's multi_logloss: 0.778079\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13463\n",
      "[417]\ttraining's multi_error: 0.30973\ttraining's multi_logloss: 0.777977\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13476\n",
      "[418]\ttraining's multi_error: 0.309885\ttraining's multi_logloss: 0.777899\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13489\n",
      "[419]\ttraining's multi_error: 0.309421\ttraining's multi_logloss: 0.777723\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13504\n",
      "[420]\ttraining's multi_error: 0.309111\ttraining's multi_logloss: 0.777647\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13508\n",
      "[421]\ttraining's multi_error: 0.308336\ttraining's multi_logloss: 0.777526\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13513\n",
      "[422]\ttraining's multi_error: 0.308181\ttraining's multi_logloss: 0.777387\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13534\n",
      "[423]\ttraining's multi_error: 0.308336\ttraining's multi_logloss: 0.777315\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13534\n",
      "[424]\ttraining's multi_error: 0.308181\ttraining's multi_logloss: 0.777143\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13547\n",
      "[425]\ttraining's multi_error: 0.308491\ttraining's multi_logloss: 0.777097\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13553\n",
      "[426]\ttraining's multi_error: 0.308336\ttraining's multi_logloss: 0.776996\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13565\n",
      "[427]\ttraining's multi_error: 0.308491\ttraining's multi_logloss: 0.776904\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13576\n",
      "[428]\ttraining's multi_error: 0.308646\ttraining's multi_logloss: 0.776782\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13583\n",
      "[429]\ttraining's multi_error: 0.308336\ttraining's multi_logloss: 0.776687\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13584\n",
      "[430]\ttraining's multi_error: 0.307716\ttraining's multi_logloss: 0.776575\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[431]\ttraining's multi_error: 0.307716\ttraining's multi_logloss: 0.776488\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13598\n",
      "[432]\ttraining's multi_error: 0.307716\ttraining's multi_logloss: 0.776384\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13609\n",
      "[433]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.776249\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13616\n",
      "[434]\ttraining's multi_error: 0.308026\ttraining's multi_logloss: 0.776163\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13624\n",
      "[435]\ttraining's multi_error: 0.307716\ttraining's multi_logloss: 0.77609\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13632\n",
      "[436]\ttraining's multi_error: 0.307871\ttraining's multi_logloss: 0.776046\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13633\n",
      "[437]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.775975\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13645\n",
      "[438]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.77586\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13649\n",
      "[439]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.775781\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13656\n",
      "[440]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.775718\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13663\n",
      "[441]\ttraining's multi_error: 0.307871\ttraining's multi_logloss: 0.775615\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13672\n",
      "[442]\ttraining's multi_error: 0.307406\ttraining's multi_logloss: 0.775545\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13671\n",
      "[443]\ttraining's multi_error: 0.307406\ttraining's multi_logloss: 0.775454\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.1368\n",
      "[444]\ttraining's multi_error: 0.307251\ttraining's multi_logloss: 0.775396\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13681\n",
      "[445]\ttraining's multi_error: 0.307251\ttraining's multi_logloss: 0.775319\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13689\n",
      "[446]\ttraining's multi_error: 0.307251\ttraining's multi_logloss: 0.775222\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13695\n",
      "[447]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.775052\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.1371\n",
      "[448]\ttraining's multi_error: 0.307871\ttraining's multi_logloss: 0.77497\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13714\n",
      "[449]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.774852\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13725\n",
      "[450]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.774622\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13736\n",
      "[451]\ttraining's multi_error: 0.307561\ttraining's multi_logloss: 0.774358\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13751\n",
      "[452]\ttraining's multi_error: 0.307251\ttraining's multi_logloss: 0.77416\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13762\n",
      "[453]\ttraining's multi_error: 0.307406\ttraining's multi_logloss: 0.773979\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13772\n",
      "[454]\ttraining's multi_error: 0.307096\ttraining's multi_logloss: 0.773706\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13776\n",
      "[455]\ttraining's multi_error: 0.306941\ttraining's multi_logloss: 0.773402\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13785\n",
      "[456]\ttraining's multi_error: 0.306786\ttraining's multi_logloss: 0.773155\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13793\n",
      "[457]\ttraining's multi_error: 0.306012\ttraining's multi_logloss: 0.772881\tvalid_1's multi_error: 0.497522\tvalid_1's multi_logloss: 1.13811\n",
      "[458]\ttraining's multi_error: 0.305392\ttraining's multi_logloss: 0.772624\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13818\n",
      "[459]\ttraining's multi_error: 0.305547\ttraining's multi_logloss: 0.772329\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.1384\n",
      "[460]\ttraining's multi_error: 0.305237\ttraining's multi_logloss: 0.77192\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.1384\n",
      "[461]\ttraining's multi_error: 0.305237\ttraining's multi_logloss: 0.77168\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13846\n",
      "[462]\ttraining's multi_error: 0.305237\ttraining's multi_logloss: 0.771301\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13866\n",
      "[463]\ttraining's multi_error: 0.304927\ttraining's multi_logloss: 0.770895\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.1388\n",
      "[464]\ttraining's multi_error: 0.305547\ttraining's multi_logloss: 0.770663\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13885\n",
      "[465]\ttraining's multi_error: 0.304927\ttraining's multi_logloss: 0.770417\tvalid_1's multi_error: 0.496902\tvalid_1's multi_logloss: 1.13897\n",
      "[466]\ttraining's multi_error: 0.303998\ttraining's multi_logloss: 0.770143\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13898\n",
      "[467]\ttraining's multi_error: 0.304152\ttraining's multi_logloss: 0.769912\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13896\n",
      "[468]\ttraining's multi_error: 0.304772\ttraining's multi_logloss: 0.769606\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13903\n",
      "[469]\ttraining's multi_error: 0.303998\ttraining's multi_logloss: 0.769361\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13902\n",
      "[470]\ttraining's multi_error: 0.303688\ttraining's multi_logloss: 0.769169\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13912\n",
      "[471]\ttraining's multi_error: 0.303068\ttraining's multi_logloss: 0.768975\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.13924\n",
      "[472]\ttraining's multi_error: 0.303378\ttraining's multi_logloss: 0.768826\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13933\n",
      "[473]\ttraining's multi_error: 0.303378\ttraining's multi_logloss: 0.768715\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13938\n",
      "[474]\ttraining's multi_error: 0.303068\ttraining's multi_logloss: 0.768615\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13945\n",
      "[475]\ttraining's multi_error: 0.303223\ttraining's multi_logloss: 0.76846\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13952\n",
      "[476]\ttraining's multi_error: 0.303223\ttraining's multi_logloss: 0.768338\tvalid_1's multi_error: 0.496283\tvalid_1's multi_logloss: 1.13966\n",
      "[477]\ttraining's multi_error: 0.303843\ttraining's multi_logloss: 0.768214\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13973\n",
      "[478]\ttraining's multi_error: 0.303378\ttraining's multi_logloss: 0.768084\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13988\n",
      "[479]\ttraining's multi_error: 0.303688\ttraining's multi_logloss: 0.767998\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.13992\n",
      "[480]\ttraining's multi_error: 0.303688\ttraining's multi_logloss: 0.767929\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14005\n",
      "[481]\ttraining's multi_error: 0.303068\ttraining's multi_logloss: 0.767854\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14011\n",
      "[482]\ttraining's multi_error: 0.303223\ttraining's multi_logloss: 0.767706\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14014\n",
      "[483]\ttraining's multi_error: 0.303378\ttraining's multi_logloss: 0.767589\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14022\n",
      "[484]\ttraining's multi_error: 0.303688\ttraining's multi_logloss: 0.767531\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14028\n",
      "[485]\ttraining's multi_error: 0.303378\ttraining's multi_logloss: 0.767479\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14039\n",
      "[486]\ttraining's multi_error: 0.303378\ttraining's multi_logloss: 0.767439\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14044\n",
      "[487]\ttraining's multi_error: 0.303223\ttraining's multi_logloss: 0.767337\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.1405\n",
      "[488]\ttraining's multi_error: 0.303223\ttraining's multi_logloss: 0.767269\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14049\n",
      "[489]\ttraining's multi_error: 0.303223\ttraining's multi_logloss: 0.767202\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14055\n",
      "[490]\ttraining's multi_error: 0.303533\ttraining's multi_logloss: 0.76709\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14054\n",
      "[491]\ttraining's multi_error: 0.303688\ttraining's multi_logloss: 0.767047\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14063\n",
      "[492]\ttraining's multi_error: 0.303843\ttraining's multi_logloss: 0.766931\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14071\n",
      "[493]\ttraining's multi_error: 0.304152\ttraining's multi_logloss: 0.766843\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14069\n",
      "[494]\ttraining's multi_error: 0.303998\ttraining's multi_logloss: 0.766785\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14075\n",
      "[495]\ttraining's multi_error: 0.303998\ttraining's multi_logloss: 0.766738\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.1408\n",
      "[496]\ttraining's multi_error: 0.303533\ttraining's multi_logloss: 0.76664\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14082\n",
      "[497]\ttraining's multi_error: 0.303533\ttraining's multi_logloss: 0.766528\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[498]\ttraining's multi_error: 0.302913\ttraining's multi_logloss: 0.766275\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14104\n",
      "[499]\ttraining's multi_error: 0.302913\ttraining's multi_logloss: 0.766103\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.1412\n",
      "[500]\ttraining's multi_error: 0.302293\ttraining's multi_logloss: 0.766005\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14129\n",
      "[501]\ttraining's multi_error: 0.302293\ttraining's multi_logloss: 0.765909\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14147\n",
      "[502]\ttraining's multi_error: 0.302138\ttraining's multi_logloss: 0.765801\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14158\n",
      "[503]\ttraining's multi_error: 0.302293\ttraining's multi_logloss: 0.765648\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14176\n",
      "[504]\ttraining's multi_error: 0.302138\ttraining's multi_logloss: 0.765434\tvalid_1's multi_error: 0.493185\tvalid_1's multi_logloss: 1.14181\n",
      "[505]\ttraining's multi_error: 0.301518\ttraining's multi_logloss: 0.765247\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14213\n",
      "[506]\ttraining's multi_error: 0.301363\ttraining's multi_logloss: 0.765098\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14237\n",
      "[507]\ttraining's multi_error: 0.301828\ttraining's multi_logloss: 0.764869\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.1426\n",
      "[508]\ttraining's multi_error: 0.301518\ttraining's multi_logloss: 0.764762\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14265\n",
      "[509]\ttraining's multi_error: 0.301673\ttraining's multi_logloss: 0.764651\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14278\n",
      "[510]\ttraining's multi_error: 0.301828\ttraining's multi_logloss: 0.764493\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14283\n",
      "[511]\ttraining's multi_error: 0.301363\ttraining's multi_logloss: 0.764327\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14292\n",
      "[512]\ttraining's multi_error: 0.300899\ttraining's multi_logloss: 0.764213\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14304\n",
      "[513]\ttraining's multi_error: 0.300744\ttraining's multi_logloss: 0.764092\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14315\n",
      "[514]\ttraining's multi_error: 0.300589\ttraining's multi_logloss: 0.763975\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14324\n",
      "[515]\ttraining's multi_error: 0.300744\ttraining's multi_logloss: 0.763923\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14331\n",
      "[516]\ttraining's multi_error: 0.300899\ttraining's multi_logloss: 0.763851\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14337\n",
      "[517]\ttraining's multi_error: 0.300899\ttraining's multi_logloss: 0.76378\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14346\n",
      "[518]\ttraining's multi_error: 0.300279\ttraining's multi_logloss: 0.763683\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14349\n",
      "[519]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.763578\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14356\n",
      "[520]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.763516\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14363\n",
      "[521]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.763417\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.1438\n",
      "[522]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.763357\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14386\n",
      "[523]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.763295\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14391\n",
      "[524]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.76326\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.144\n",
      "[525]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.763226\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14408\n",
      "[526]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.763207\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.1441\n",
      "[527]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.763163\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14416\n",
      "[528]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.76312\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14422\n",
      "[529]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.763082\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14424\n",
      "[530]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.762948\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14427\n",
      "[531]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762884\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14433\n",
      "[532]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.762859\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14439\n",
      "[533]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.762824\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14443\n",
      "[534]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762777\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14448\n",
      "[535]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762609\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14464\n",
      "[536]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762589\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14467\n",
      "[537]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762574\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.1447\n",
      "[538]\ttraining's multi_error: 0.300279\ttraining's multi_logloss: 0.762558\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14473\n",
      "[539]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762543\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14475\n",
      "[540]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762541\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14476\n",
      "[541]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762526\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14477\n",
      "[542]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762522\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14478\n",
      "[543]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762516\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14479\n",
      "[544]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.762513\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14479\n",
      "[545]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762507\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.1448\n",
      "[546]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762493\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14482\n",
      "[547]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.76249\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14482\n",
      "[548]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762488\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14482\n",
      "[549]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762486\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14483\n",
      "[550]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762421\tvalid_1's multi_error: 0.495663\tvalid_1's multi_logloss: 1.14486\n",
      "[551]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762292\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14494\n",
      "[552]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762201\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14502\n",
      "[553]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.76219\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14504\n",
      "[554]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.762189\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14505\n",
      "[555]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762185\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14505\n",
      "[556]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762182\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14505\n",
      "[557]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762165\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14506\n",
      "[558]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762132\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.1451\n",
      "[559]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.762076\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14513\n",
      "[560]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.76206\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14514\n",
      "[561]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.762023\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14514\n",
      "[562]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761967\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14514\n",
      "[563]\ttraining's multi_error: 0.299814\ttraining's multi_logloss: 0.761913\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14514\n",
      "[564]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761825\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14525\n",
      "[565]\ttraining's multi_error: 0.300124\ttraining's multi_logloss: 0.761804\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[566]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761728\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14531\n",
      "[567]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761626\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14528\n",
      "[568]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761549\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14532\n",
      "[569]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761479\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14531\n",
      "[570]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761464\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14535\n",
      "[571]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761463\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14535\n",
      "[572]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761463\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14535\n",
      "[573]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761462\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14535\n",
      "[574]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761461\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14536\n",
      "[575]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761444\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14538\n",
      "[576]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761427\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14541\n",
      "[577]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761416\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14543\n",
      "[578]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761415\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14543\n",
      "[579]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761415\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14543\n",
      "[580]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761414\tvalid_1's multi_error: 0.495043\tvalid_1's multi_logloss: 1.14543\n",
      "[581]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.761384\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14545\n",
      "[582]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.76133\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14548\n",
      "[583]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.761329\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14548\n",
      "[584]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.761328\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14548\n",
      "[585]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.761307\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.1455\n",
      "[586]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761286\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14551\n",
      "[587]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761286\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14551\n",
      "[588]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761286\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14551\n",
      "[589]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761285\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14551\n",
      "[590]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761267\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14553\n",
      "[591]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761266\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14553\n",
      "[592]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761266\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14553\n",
      "[593]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761248\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14554\n",
      "[594]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761248\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14554\n",
      "[595]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761248\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14554\n",
      "[596]\ttraining's multi_error: 0.298729\ttraining's multi_logloss: 0.761248\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14554\n",
      "[597]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761232\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14556\n",
      "[598]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761232\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14556\n",
      "[599]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761231\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14556\n",
      "[600]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.761216\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14557\n",
      "[601]\ttraining's multi_error: 0.299039\ttraining's multi_logloss: 0.761216\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14557\n",
      "[602]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761202\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14559\n",
      "[603]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761193\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14561\n",
      "[604]\ttraining's multi_error: 0.298884\ttraining's multi_logloss: 0.761193\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14561\n",
      "[605]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.76118\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14563\n",
      "[606]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.76118\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14563\n",
      "[607]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761179\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14563\n",
      "[608]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761179\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14563\n",
      "[609]\ttraining's multi_error: 0.299194\ttraining's multi_logloss: 0.761179\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14563\n",
      "[610]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761166\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14564\n",
      "[611]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761166\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14564\n",
      "[612]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761166\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14564\n",
      "[613]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761165\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14564\n",
      "[614]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761154\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14565\n",
      "[615]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761154\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14565\n",
      "[616]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761154\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14565\n",
      "[617]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761153\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14565\n",
      "[618]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761153\tvalid_1's multi_error: 0.494424\tvalid_1's multi_logloss: 1.14565\n",
      "[619]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761142\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14566\n",
      "[620]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761142\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14566\n",
      "[621]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761142\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14566\n",
      "[622]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761142\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14566\n",
      "[623]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761134\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14568\n",
      "[624]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761134\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14568\n",
      "[625]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761133\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14568\n",
      "[626]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761133\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14568\n",
      "[627]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761123\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14569\n",
      "[628]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761123\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14569\n",
      "[629]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761122\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14569\n",
      "[630]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761122\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14569\n",
      "[631]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761116\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[632]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761116\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[633]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761116\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[634]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761116\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[635]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761116\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[636]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761115\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[637]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761115\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[638]\ttraining's multi_error: 0.299349\ttraining's multi_logloss: 0.761115\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14571\n",
      "[639]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761109\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14573\n",
      "[640]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761109\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14572\n",
      "[641]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761109\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14572\n",
      "[642]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761109\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14572\n",
      "[643]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761108\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14572\n",
      "[644]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761099\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[645]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761099\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14573\n",
      "[646]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761099\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14573\n",
      "[647]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761099\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14573\n",
      "[648]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761099\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14573\n",
      "[649]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761092\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14574\n",
      "[650]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761092\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14574\n",
      "[651]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761092\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14574\n",
      "[652]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761092\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14574\n",
      "[653]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761091\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14574\n",
      "[654]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.761091\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14574\n",
      "[655]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761083\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14575\n",
      "[656]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761083\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14575\n",
      "[657]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761082\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14575\n",
      "[658]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761082\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14575\n",
      "[659]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761076\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14576\n",
      "[660]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761075\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[661]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761042\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[662]\ttraining's multi_error: 0.299504\ttraining's multi_logloss: 0.761041\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[663]\ttraining's multi_error: 0.299659\ttraining's multi_logloss: 0.76102\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[664]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[665]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[666]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[667]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[668]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[669]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[670]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[671]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[672]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[673]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[674]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[675]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[676]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[677]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[678]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[679]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[680]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[681]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[682]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[683]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[684]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[685]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[686]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[687]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[688]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[689]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[690]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[691]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[692]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[693]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[694]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[695]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[696]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[697]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[698]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[699]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[700]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[701]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[702]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[703]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[704]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[705]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[706]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[707]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[708]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[709]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[710]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[711]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[712]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[713]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[714]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[715]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[716]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[717]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[718]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[719]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[720]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[721]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[722]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[723]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[724]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[725]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[726]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[727]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[728]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[729]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[730]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[731]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[732]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[733]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[734]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[735]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[736]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[737]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[738]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[739]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[740]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[741]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[742]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[743]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[744]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[745]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[746]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[747]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[748]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[749]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[750]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[751]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[752]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[753]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[754]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[755]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[756]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[757]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[758]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[759]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[760]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[761]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[762]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[763]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[764]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[765]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[766]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[767]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[768]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[769]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[770]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[771]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[772]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[773]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[774]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[775]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[776]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[777]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[778]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[779]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[780]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[781]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[782]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[783]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[784]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[785]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[786]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[787]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[788]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[789]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[790]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[791]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[792]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[793]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[794]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[795]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[796]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[797]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[798]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[799]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[800]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[801]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[802]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[803]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[804]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[805]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[806]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[807]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[808]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[809]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[810]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[811]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[812]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[813]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[814]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[815]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[816]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[817]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[818]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[819]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[820]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[821]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[822]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[823]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[824]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[825]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[826]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[827]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[828]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[829]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[830]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[831]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[832]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[833]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[834]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[835]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[836]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[837]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[838]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[839]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[840]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[841]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[842]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[843]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[844]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[845]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[846]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[847]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[848]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[849]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[850]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[851]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[852]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[853]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[854]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[855]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[856]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[857]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[858]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[859]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[860]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[861]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[862]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[863]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[864]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[865]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[866]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[867]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[868]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[869]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[870]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[871]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[872]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[873]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[874]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[875]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[876]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[877]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[878]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[879]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[880]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[881]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[882]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[883]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[884]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[885]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[886]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[887]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[888]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[889]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[890]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[891]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[892]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[893]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[894]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[895]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[896]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[897]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[898]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[899]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[900]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[901]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[902]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[903]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[904]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[905]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[906]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[907]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[908]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[909]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[910]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[911]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[912]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[913]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[914]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[915]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[916]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[917]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[918]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[919]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[920]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[921]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[922]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[923]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[924]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[925]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[926]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[927]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[928]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[929]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[930]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[931]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[932]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[933]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[934]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[935]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[936]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[937]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[938]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[939]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[940]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[941]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[942]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[943]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[944]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[945]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[946]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[947]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[948]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[949]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[950]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[951]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[952]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[953]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[954]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[955]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[956]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[957]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[958]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[959]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[960]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[961]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[962]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[963]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[964]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[965]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[966]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[967]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[968]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[969]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[970]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[971]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[972]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[973]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[974]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[975]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[976]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[977]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[978]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[979]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[980]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[981]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[982]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[983]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[984]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[985]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[986]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[987]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[988]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[989]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[990]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[991]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[992]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[993]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[994]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[995]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[996]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[997]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[998]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[999]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1000]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1001]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1002]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1003]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1004]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1005]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1006]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1007]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1008]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1009]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1010]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1011]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1012]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1013]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1014]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1015]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1016]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1017]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1018]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1019]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1020]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1021]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1022]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1023]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1024]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1025]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1026]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1027]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1028]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1029]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1030]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1031]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1032]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1033]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1034]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1035]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1036]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1037]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1038]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1039]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1040]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1041]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1042]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1043]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1044]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1045]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "[1046]\ttraining's multi_error: 0.299969\ttraining's multi_logloss: 0.761\tvalid_1's multi_error: 0.493804\tvalid_1's multi_logloss: 1.14577\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's multi_error: 0.40657\ttraining's multi_logloss: 0.971203\tvalid_1's multi_error: 0.467162\tvalid_1's multi_logloss: 1.07586\n",
      "Eval ACC: 0.5328376703841388\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier(**params)\n",
    "    \n",
    "clf.fit(X_train, y_train, early_stopping_rounds=1000, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric='multi_error', verbose=True)\n",
    "\n",
    "eval_score = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "print('Eval ACC: {}'.format(eval_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 18, 'n_estimators': 46, 'objective': 'multiclass', 'boosting_type': 'gbdt', 'subsample': 0.7, 'colsample_bytree': 1, 'min_data_in_leaf': 55, 'reg_alpha': 1, 'reg_lambda': 1}\n"
     ]
    }
   ],
   "source": [
    "best_iter = clf.best_iteration_\n",
    "params['n_estimators'] = best_iter\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightgbm import plot_importance\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plot_importance(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458989</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458994</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458996</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459001</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>467954</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>467958</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>467960</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>467961</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>467968</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Segmentation\n",
       "0     458989            A\n",
       "1     458994            A\n",
       "2     458996            A\n",
       "3     459000            A\n",
       "4     459001            A\n",
       "...      ...          ...\n",
       "2622  467954            A\n",
       "2623  467958            A\n",
       "2624  467960            A\n",
       "2625  467961            A\n",
       "2626  467968            A\n",
       "\n",
       "[2627 rows x 2 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Segmentation'] = clf.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Segmentation'] = sub['Segmentation'].map({0:\"A\" ,1:\"B\",2:\"C\",3:\"D\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458989</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458994</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458996</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459000</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459001</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>467954</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>467958</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>467960</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>467961</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>467968</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Segmentation\n",
       "0     458989            A\n",
       "1     458994            C\n",
       "2     458996            A\n",
       "3     459000            A\n",
       "4     459001            D\n",
       "...      ...          ...\n",
       "2622  467954            D\n",
       "2623  467958            A\n",
       "2624  467960            A\n",
       "2625  467961            A\n",
       "2626  467968            D\n",
       "\n",
       "[2627 rows x 2 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sub.merge(commonIDlist,on='ID',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segmentation_x</th>\n",
       "      <th>Segmentation_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458989</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458994</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458996</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459000</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459001</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>467954</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>467958</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>467960</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>467961</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>467968</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2627 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Segmentation_x Segmentation_y\n",
       "0     458989              A              B\n",
       "1     458994              C              C\n",
       "2     458996              A              A\n",
       "3     459000              A              C\n",
       "4     459001              D              C\n",
       "...      ...            ...            ...\n",
       "2622  467954              D              D\n",
       "2623  467958              A              A\n",
       "2624  467960              A            NaN\n",
       "2625  467961              A              B\n",
       "2626  467968              D            NaN\n",
       "\n",
       "[2627 rows x 3 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['Segmentation'] = np.where(temp['Segmentation_y'].isna(),sub['Segmentation'],temp['Segmentation_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458989</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458994</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458996</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>459001</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>467954</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>467958</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2624</th>\n",
       "      <td>467960</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>467961</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2626</th>\n",
       "      <td>467968</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Segmentation\n",
       "0     458989            B\n",
       "1     458994            C\n",
       "2     458996            A\n",
       "3     459000            C\n",
       "4     459001            C\n",
       "...      ...          ...\n",
       "2622  467954            D\n",
       "2623  467958            A\n",
       "2624  467960            A\n",
       "2625  467961            B\n",
       "2626  467968            D\n",
       "\n",
       "[2627 rows x 2 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    726\n",
       "D    717\n",
       "C    640\n",
       "B    544\n",
       "Name: Segmentation, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Segmentation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
