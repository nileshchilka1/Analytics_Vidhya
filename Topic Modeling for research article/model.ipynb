{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',None)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reconstructing Subject-Specific Effect Maps</td>\n",
       "      <td>Predictive models allow subject-specific inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rotation Invariance Neural Network</td>\n",
       "      <td>Rotation invariance and translation invarian...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Spherical polyharmonics and Poisson kernels fo...</td>\n",
       "      <td>We introduce and develop the notion of spher...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A finite element approximation for the stochas...</td>\n",
       "      <td>The stochastic Landau--Lifshitz--Gilbert (LL...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comparative study of Discrete Wavelet Transfor...</td>\n",
       "      <td>Fourier-transform infra-red (FTIR) spectra o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20967</th>\n",
       "      <td>20968</td>\n",
       "      <td>Contemporary machine learning: a guide for pra...</td>\n",
       "      <td>Machine learning is finding increasingly bro...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20968</th>\n",
       "      <td>20969</td>\n",
       "      <td>Uniform diamond coatings on WC-Co hard alloy c...</td>\n",
       "      <td>Polycrystalline diamond coatings have been g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20969</th>\n",
       "      <td>20970</td>\n",
       "      <td>Analysing Soccer Games with Clustering and Con...</td>\n",
       "      <td>We present a new approach for identifying si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20970</th>\n",
       "      <td>20971</td>\n",
       "      <td>On the Efficient Simulation of the Left-Tail o...</td>\n",
       "      <td>The sum of Log-normal variates is encountere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20971</th>\n",
       "      <td>20972</td>\n",
       "      <td>Why optional stopping is a problem for Bayesians</td>\n",
       "      <td>Recently, optional stopping has been a subje...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20972 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TITLE  \\\n",
       "0          1        Reconstructing Subject-Specific Effect Maps   \n",
       "1          2                 Rotation Invariance Neural Network   \n",
       "2          3  Spherical polyharmonics and Poisson kernels fo...   \n",
       "3          4  A finite element approximation for the stochas...   \n",
       "4          5  Comparative study of Discrete Wavelet Transfor...   \n",
       "...      ...                                                ...   \n",
       "20967  20968  Contemporary machine learning: a guide for pra...   \n",
       "20968  20969  Uniform diamond coatings on WC-Co hard alloy c...   \n",
       "20969  20970  Analysing Soccer Games with Clustering and Con...   \n",
       "20970  20971  On the Efficient Simulation of the Left-Tail o...   \n",
       "20971  20972   Why optional stopping is a problem for Bayesians   \n",
       "\n",
       "                                                ABSTRACT  Computer Science  \\\n",
       "0        Predictive models allow subject-specific inf...                 1   \n",
       "1        Rotation invariance and translation invarian...                 1   \n",
       "2        We introduce and develop the notion of spher...                 0   \n",
       "3        The stochastic Landau--Lifshitz--Gilbert (LL...                 0   \n",
       "4        Fourier-transform infra-red (FTIR) spectra o...                 1   \n",
       "...                                                  ...               ...   \n",
       "20967    Machine learning is finding increasingly bro...                 1   \n",
       "20968    Polycrystalline diamond coatings have been g...                 0   \n",
       "20969    We present a new approach for identifying si...                 1   \n",
       "20970    The sum of Log-normal variates is encountere...                 0   \n",
       "20971    Recently, optional stopping has been a subje...                 0   \n",
       "\n",
       "       Physics  Mathematics  Statistics  Quantitative Biology  \\\n",
       "0            0            0           0                     0   \n",
       "1            0            0           0                     0   \n",
       "2            0            1           0                     0   \n",
       "3            0            1           0                     0   \n",
       "4            0            0           1                     0   \n",
       "...        ...          ...         ...                   ...   \n",
       "20967        1            0           0                     0   \n",
       "20968        1            0           0                     0   \n",
       "20969        0            0           0                     0   \n",
       "20970        0            1           1                     0   \n",
       "20971        0            1           1                     0   \n",
       "\n",
       "       Quantitative Finance  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "...                     ...  \n",
       "20967                     0  \n",
       "20968                     0  \n",
       "20969                     0  \n",
       "20970                     0  \n",
       "20971                     0  \n",
       "\n",
       "[20972 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20973</td>\n",
       "      <td>Closed-form Marginal Likelihood in Gamma-Poiss...</td>\n",
       "      <td>We present novel understandings of the Gamma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20974</td>\n",
       "      <td>Laboratory mid-IR spectra of equilibrated and ...</td>\n",
       "      <td>Meteorites contain minerals from Solar Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20975</td>\n",
       "      <td>Case For Static AMSDU Aggregation in WLANs</td>\n",
       "      <td>Frame aggregation is a mechanism by which mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20976</td>\n",
       "      <td>The $Gaia$-ESO Survey: the inner disk intermed...</td>\n",
       "      <td>Milky Way open clusters are very diverse in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20977</td>\n",
       "      <td>Witness-Functions versus Interpretation-Functi...</td>\n",
       "      <td>Proving that a cryptographic protocol is cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>29957</td>\n",
       "      <td>Supporting mixed-datatype matrix multiplicatio...</td>\n",
       "      <td>We approach the problem of implementing mixe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>29958</td>\n",
       "      <td>An axiomatic basis for Blackwell optimality</td>\n",
       "      <td>In the theory of Markov decision processes (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>29959</td>\n",
       "      <td>GeneVis - An interactive visualization tool fo...</td>\n",
       "      <td>GeneVis is a web-based tool to visualize com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>29960</td>\n",
       "      <td>Quantifying the causal effect of speed cameras...</td>\n",
       "      <td>This paper quantifies the effect of speed ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>29961</td>\n",
       "      <td>Cube-magic labelings of grids</td>\n",
       "      <td>We show that the vertices and edges of a $d$...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              TITLE  \\\n",
       "0     20973  Closed-form Marginal Likelihood in Gamma-Poiss...   \n",
       "1     20974  Laboratory mid-IR spectra of equilibrated and ...   \n",
       "2     20975         Case For Static AMSDU Aggregation in WLANs   \n",
       "3     20976  The $Gaia$-ESO Survey: the inner disk intermed...   \n",
       "4     20977  Witness-Functions versus Interpretation-Functi...   \n",
       "...     ...                                                ...   \n",
       "8984  29957  Supporting mixed-datatype matrix multiplicatio...   \n",
       "8985  29958        An axiomatic basis for Blackwell optimality   \n",
       "8986  29959  GeneVis - An interactive visualization tool fo...   \n",
       "8987  29960  Quantifying the causal effect of speed cameras...   \n",
       "8988  29961                      Cube-magic labelings of grids   \n",
       "\n",
       "                                               ABSTRACT  \n",
       "0       We present novel understandings of the Gamma...  \n",
       "1       Meteorites contain minerals from Solar Syste...  \n",
       "2       Frame aggregation is a mechanism by which mu...  \n",
       "3       Milky Way open clusters are very diverse in ...  \n",
       "4       Proving that a cryptographic protocol is cor...  \n",
       "...                                                 ...  \n",
       "8984    We approach the problem of implementing mixe...  \n",
       "8985    In the theory of Markov decision processes (...  \n",
       "8986    GeneVis is a web-based tool to visualize com...  \n",
       "8987    This paper quantifies the effect of speed ca...  \n",
       "8988    We show that the vertices and edges of a $d$...  \n",
       "\n",
       "[8989 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('ID',axis=1,inplace=True)\n",
    "test_df.drop('ID',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = list(train_df.columns[2:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['word_count_ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: len(str(x).split(\" \"))) \n",
    "train_df['word_count_TITLE'] = train_df['TITLE'].apply(lambda x: len(str(x).split(\" \"))) \n",
    "\n",
    "test_df['word_count_ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: len(str(x).split(\" \"))) \n",
    "test_df['word_count_TITLE'] = test_df['TITLE'].apply(lambda x: len(str(x).split(\" \"))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "    words = sentence.split()    \n",
    "    return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['avg_word_ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: avg_word(x))\n",
    "train_df['avg_word_TITLE'] = train_df['TITLE'].apply(lambda x: avg_word(x))\n",
    "\n",
    "test_df['avg_word_ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: avg_word(x))\n",
    "test_df['avg_word_TITLE'] = test_df['TITLE'].apply(lambda x: avg_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stopwords_ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train_df['stopwords_TITLE'] = train_df['TITLE'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "test_df['stopwords_ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "test_df['stopwords_TITLE'] = test_df['TITLE'].apply(lambda x: len([x for x in x.split() if x in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['numerics_ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "train_df['numerics_TITLE'] = train_df['TITLE'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "test_df['numerics_ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "test_df['numerics_TITLE'] = test_df['TITLE'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ABSTRACT'] = train_df['ABSTRACT'].str.replace('[^\\w\\s]','')\n",
    "train_df['TITLE'] = train_df['TITLE'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "test_df['ABSTRACT'] = test_df['ABSTRACT'].str.replace('[^\\w\\s]','')\n",
    "test_df['TITLE'] = test_df['TITLE'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['non_alphanumerics_ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if not x.isalnum()]))\n",
    "train_df['non_alphanumerics_TITLE'] = train_df['TITLE'].apply(lambda x: len([x for x in x.split() if not x.isalnum()]))\n",
    "\n",
    "test_df['non_alphanumerics_ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if not x.isalnum()]))\n",
    "test_df['non_alphanumerics_TITLE'] = test_df['TITLE'].apply(lambda x: len([x for x in x.split() if not x.isalnum()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['upper_case_ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "train_df['upper_case_TITLE'] = train_df['TITLE'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "test_df['upper_case_ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "test_df['upper_case_TITLE'] = test_df['TITLE'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train_df['TITLE'] = train_df['TITLE'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "test_df['ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "test_df['TITLE'] = test_df['TITLE'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ABSTRACT'] = train_df['ABSTRACT'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train_df['TITLE'] = train_df['TITLE'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "test_df['ABSTRACT'] = test_df['ABSTRACT'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "test_df['TITLE'] = test_df['TITLE'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       closedform margin likelihood gammapoisson matr...\n",
       "1       laboratori midir spectra equilibr igneou meteo...\n",
       "2                           case static amsdu aggreg wlan\n",
       "3       gaiaeso survey inner disk intermediateag open ...\n",
       "4       witnessfunct versu interpretationfunct secreci...\n",
       "                              ...                        \n",
       "8984    support mixeddatatyp matrix multipl within bli...\n",
       "8985                          axiomat basi blackwel optim\n",
       "8986    genevi interact visual tool combin crossdiscip...\n",
       "8987    quantifi causal effect speed camera road traff...\n",
       "8988                                   cubemag label grid\n",
       "Name: TITLE, Length: 8989, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "st = PorterStemmer()\n",
    "lm = WordNetLemmatizer()\n",
    "\n",
    "train_df['ABSTRACT'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "train_df['TITLE'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "test_df['ABSTRACT'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "test_df['TITLE'].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feature in target_features:\n",
    "    sns.countplot(x=feature,data=train_df)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('count')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feature in target_features:\n",
    "    sns.countplot(x=feature,data=train_df[train_df['Quantitative Biology']==1])\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for feature in target_features:\n",
    "    sns.countplot(x=feature,data=train_df[train_df['Quantitative Finance']==1])\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sns.heatmap(train_df[2:8].corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "count = 0\n",
    "for feature in target_features:\n",
    "    target_feature = target_features.copy()\n",
    "    target_feature.remove(feature)\n",
    "    positive_df = train_df[train_df[feature]==1]\n",
    "    length=len(positive_df)\n",
    "    #extra_positive_df = train_df[train_df[feature]==1].sample(int(length),random_state=0,replace=True)\n",
    "    positive_df = pd.concat([positive_df,positive_df],axis=0)\n",
    "    if count == 4 or count == 5:\n",
    "        negative_df = train_df[train_df[feature]==0].sample(int(3*length),random_state=0)\n",
    "    else:\n",
    "        negative_df = train_df[train_df[feature]==0].sample(int(2*length),random_state=0,replace=True)\n",
    "    df = pd.concat([positive_df,negative_df],axis=0)\n",
    "    df.drop(target_feature,axis=1,inplace=True)\n",
    "    l.append(df)\n",
    "    count+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>word_count_ABSTRACT</th>\n",
       "      <th>word_count_TITLE</th>\n",
       "      <th>avg_word_ABSTRACT</th>\n",
       "      <th>avg_word_TITLE</th>\n",
       "      <th>stopwords_ABSTRACT</th>\n",
       "      <th>stopwords_TITLE</th>\n",
       "      <th>numerics_ABSTRACT</th>\n",
       "      <th>numerics_TITLE</th>\n",
       "      <th>non_alphanumerics_ABSTRACT</th>\n",
       "      <th>non_alphanumerics_TITLE</th>\n",
       "      <th>upper_case_ABSTRACT</th>\n",
       "      <th>upper_case_TITLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>closedform marginal likelihood gammapoisson ma...</td>\n",
       "      <td>present novel understandings gammapoisson gap ...</td>\n",
       "      <td>89</td>\n",
       "      <td>7</td>\n",
       "      <td>6.218750</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laboratory midir spectra equilibrated igneous ...</td>\n",
       "      <td>meteorites contain minerals solar system aster...</td>\n",
       "      <td>125</td>\n",
       "      <td>14</td>\n",
       "      <td>5.844444</td>\n",
       "      <td>7.214286</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>case static amsdu aggregation wlans</td>\n",
       "      <td>frame aggregation mechanism multiple frames co...</td>\n",
       "      <td>118</td>\n",
       "      <td>7</td>\n",
       "      <td>5.563492</td>\n",
       "      <td>5.142857</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaiaeso survey inner disk intermediateage open...</td>\n",
       "      <td>milky way open clusters diverse terms age chem...</td>\n",
       "      <td>248</td>\n",
       "      <td>11</td>\n",
       "      <td>5.332090</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>witnessfunctions versus interpretationfunction...</td>\n",
       "      <td>proving cryptographic protocol correct secrecy...</td>\n",
       "      <td>111</td>\n",
       "      <td>11</td>\n",
       "      <td>5.529412</td>\n",
       "      <td>8.636364</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>supporting mixeddatatype matrix multiplication...</td>\n",
       "      <td>approach problem implementing mixeddatatype su...</td>\n",
       "      <td>183</td>\n",
       "      <td>8</td>\n",
       "      <td>6.040201</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>axiomatic basis blackwell optimality</td>\n",
       "      <td>theory markov decision processes mdps blackwel...</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>5.478261</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>genevis interactive visualization tool combini...</td>\n",
       "      <td>genevis webbased tool visualize complementary ...</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>6.043011</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>quantifying causal effect speed cameras road t...</td>\n",
       "      <td>paper quantifies effect speed cameras road tra...</td>\n",
       "      <td>147</td>\n",
       "      <td>18</td>\n",
       "      <td>5.805031</td>\n",
       "      <td>5.944444</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>cubemagic labelings grids</td>\n",
       "      <td>show vertices edges ddimensional grid graph gv...</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>5.442857</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TITLE  \\\n",
       "0     closedform marginal likelihood gammapoisson ma...   \n",
       "1     laboratory midir spectra equilibrated igneous ...   \n",
       "2                   case static amsdu aggregation wlans   \n",
       "3     gaiaeso survey inner disk intermediateage open...   \n",
       "4     witnessfunctions versus interpretationfunction...   \n",
       "...                                                 ...   \n",
       "8984  supporting mixeddatatype matrix multiplication...   \n",
       "8985               axiomatic basis blackwell optimality   \n",
       "8986  genevis interactive visualization tool combini...   \n",
       "8987  quantifying causal effect speed cameras road t...   \n",
       "8988                          cubemagic labelings grids   \n",
       "\n",
       "                                               ABSTRACT  word_count_ABSTRACT  \\\n",
       "0     present novel understandings gammapoisson gap ...                   89   \n",
       "1     meteorites contain minerals solar system aster...                  125   \n",
       "2     frame aggregation mechanism multiple frames co...                  118   \n",
       "3     milky way open clusters diverse terms age chem...                  248   \n",
       "4     proving cryptographic protocol correct secrecy...                  111   \n",
       "...                                                 ...                  ...   \n",
       "8984  approach problem implementing mixeddatatype su...                  183   \n",
       "8985  theory markov decision processes mdps blackwel...                   45   \n",
       "8986  genevis webbased tool visualize complementary ...                   87   \n",
       "8987  paper quantifies effect speed cameras road tra...                  147   \n",
       "8988  show vertices edges ddimensional grid graph gv...                   67   \n",
       "\n",
       "      word_count_TITLE  avg_word_ABSTRACT  avg_word_TITLE  stopwords_ABSTRACT  \\\n",
       "0                    7           6.218750        9.000000                  31   \n",
       "1                   14           5.844444        7.214286                  41   \n",
       "2                    7           5.563492        5.142857                  43   \n",
       "3                   11           5.332090        6.000000                  88   \n",
       "4                   11           5.529412        8.636364                  53   \n",
       "...                ...                ...             ...                 ...   \n",
       "8984                 8           6.040201        8.250000                  68   \n",
       "8985                 6           5.478261        6.333333                  14   \n",
       "8986                12           6.043011        7.333333                  30   \n",
       "8987                18           5.805031        5.944444                  45   \n",
       "8988                 4           5.442857        6.500000                  31   \n",
       "\n",
       "      stopwords_TITLE  numerics_ABSTRACT  numerics_TITLE  \\\n",
       "0                   1                  0               0   \n",
       "1                   4                  0               0   \n",
       "2                   1                  0               0   \n",
       "3                   1                  6               1   \n",
       "4                   3                  0               0   \n",
       "...               ...                ...             ...   \n",
       "8984                1                  1               0   \n",
       "8985                1                  0               0   \n",
       "8986                1                  0               0   \n",
       "8987                4                  0               0   \n",
       "8988                1                  0               0   \n",
       "\n",
       "      non_alphanumerics_ABSTRACT  non_alphanumerics_TITLE  \\\n",
       "0                              0                        0   \n",
       "1                              0                        0   \n",
       "2                              0                        0   \n",
       "3                              1                        0   \n",
       "4                              0                        0   \n",
       "...                          ...                      ...   \n",
       "8984                           0                        0   \n",
       "8985                           0                        0   \n",
       "8986                           0                        0   \n",
       "8987                           0                        0   \n",
       "8988                           2                        0   \n",
       "\n",
       "      upper_case_ABSTRACT  upper_case_TITLE  \n",
       "0                       0                 0  \n",
       "1                       0                 0  \n",
       "2                       7                 1  \n",
       "3                      13                 1  \n",
       "4                       0                 0  \n",
       "...                   ...               ...  \n",
       "8984                    7                 1  \n",
       "8985                    0                 0  \n",
       "8986                    0                 0  \n",
       "8987                    9                 0  \n",
       "8988                    3                 0  \n",
       "\n",
       "[8989 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer Science',\n",
       " 'Physics',\n",
       " 'Mathematics',\n",
       " 'Statistics',\n",
       " 'Quantitative Biology',\n",
       " 'Quantitative Finance']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df = l[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target = train_df[target_features[num]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV = CountVectorizer(max_features=1500,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df0 = CV.fit_transform(train_df['ABSTRACT']).toarray()\n",
    "test_df0 = CV.transform(test_df['ABSTRACT']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df1 = CV.fit_transform(train_df['TITLE']).toarray()\n",
    "test_df1 = CV.transform(test_df['TITLE']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df0 = pd.DataFrame(train_df0)\n",
    "train_df1 = pd.DataFrame(train_df1,columns=list(range(1500,3000)))\n",
    "\n",
    "test_df0 = pd.DataFrame(test_df0)\n",
    "test_df1 = pd.DataFrame(test_df1,columns=list(range(1500,3000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_bog_df = pd.concat([train_df0,train_df1],axis=1)\n",
    "test_bog_df = pd.concat([test_df0,test_df1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_bog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_bog_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df.drop(['TITLE','ABSTRACT',target_features[num]],axis=1,inplace=True)\n",
    "\n",
    "test_df.drop(['TITLE','ABSTRACT'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df.reset_index(drop=True,inplace=True)\n",
    "test_df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df = pd.concat([train_df,train_bog_df],axis=1)\n",
    "\n",
    "test_df = pd.concat([test_df,test_bog_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(train_df,target,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = MultinomialNB(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion_matrix(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_predict = model.predict(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.Series(y_predict).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_copy = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "df_predict = []\n",
    "for i,df in enumerate(l):\n",
    "    print(i)\n",
    "        \n",
    "    test_df = test_df_copy.copy()\n",
    "    train_df = df\n",
    "    target = train_df[target_features[i]]\n",
    "    \n",
    "    \n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    \n",
    "\n",
    "    CV = CountVectorizer(max_features=7500,ngram_range=(1,3))\n",
    "    \n",
    "    train_df0 = CV.fit_transform(train_df['TITLE']).toarray()\n",
    "    test_df0 = CV.transform(test_df['TITLE']).toarray()\n",
    "   \n",
    "    \n",
    "    CV = CountVectorizer(max_features=14000,ngram_range=(1,3))\n",
    "\n",
    "    train_df1 = CV.fit_transform(train_df['ABSTRACT']).toarray()\n",
    "    test_df1 = CV.transform(test_df['ABSTRACT']).toarray()\n",
    "    \n",
    "    \n",
    "\n",
    "    train_df0 = pd.DataFrame(train_df0)\n",
    "    train_df1 = pd.DataFrame(train_df1,columns=list(range(7500,21500)))\n",
    "\n",
    "    test_df0 = pd.DataFrame(test_df0)\n",
    "    test_df1 = pd.DataFrame(test_df1,columns=list(range(7500,21500)))\n",
    "\n",
    "    train_bog_df = pd.concat([train_df0,train_df1],axis=1)\n",
    "    del train_df0,train_df1\n",
    "    test_bog_df = pd.concat([test_df0,test_df1],axis=1)\n",
    "    del test_df0,test_df1\n",
    "    train_df.drop(['TITLE','ABSTRACT',target_features[i]],axis=1,inplace=True)\n",
    "    test_df.drop(['TITLE','ABSTRACT'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    train_df.reset_index(drop=True,inplace=True)\n",
    "    test_df.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    train_df = pd.concat([train_df,train_bog_df],axis=1)\n",
    "    del train_bog_df\n",
    "    test_df = pd.concat([test_df,test_bog_df],axis=1)\n",
    "    del test_bog_df\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "    model = MultinomialNB(alpha=1)\n",
    "\n",
    "    model.fit(train_df,target)\n",
    "\n",
    "    y_predict = model.predict(test_df)\n",
    "    del model\n",
    "    df_predict.append(pd.Series(y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_predict = pd.DataFrame(df_predict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_predict.columns = target_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Statistics</th>\n",
       "      <th>Quantitative Biology</th>\n",
       "      <th>Quantitative Finance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8989 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Computer Science  Physics  Mathematics  Statistics  \\\n",
       "0                    1        0            0           1   \n",
       "1                    0        1            0           0   \n",
       "2                    1        0            0           0   \n",
       "3                    0        1            0           0   \n",
       "4                    1        0            0           0   \n",
       "...                ...      ...          ...         ...   \n",
       "8984                 1        0            0           0   \n",
       "8985                 1        0            1           0   \n",
       "8986                 1        0            0           1   \n",
       "8987                 1        0            0           1   \n",
       "8988                 0        0            1           0   \n",
       "\n",
       "      Quantitative Biology  Quantitative Finance  \n",
       "0                        0                     0  \n",
       "1                        0                     0  \n",
       "2                        0                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  \n",
       "...                    ...                   ...  \n",
       "8984                     0                     0  \n",
       "8985                     0                     0  \n",
       "8986                     1                     0  \n",
       "8987                     0                     0  \n",
       "8988                     0                     0  \n",
       "\n",
       "[8989 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8889\n",
       "1     100\n",
       "Name: Quantitative Finance, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_predict['Quantitative Finance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission_UVKGLZE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.drop(target_features,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.concat([sub,df_full_predict],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
